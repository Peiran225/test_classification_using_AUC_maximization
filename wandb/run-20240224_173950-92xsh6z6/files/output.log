Proportion of positive examples: 0.00010072860356579256
pad token id is none
finishing tokeninzing
trainable params: 12,288 || all params: 124,453,632 || trainable%: 0.009873556763694932
Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
02/24/2024 17:40:04 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  0%|          | 0/28 [00:00<?, ?it/s]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 11%|█         | 3/28 [00:00<00:01, 21.53it/s]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 21%|██▏       | 6/28 [00:00<00:01, 16.81it/s]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 29%|██▊       | 8/28 [00:00<00:01, 15.90it/s]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 36%|███▌      | 10/28 [00:00<00:01, 15.40it/s]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
balanced data AUC before train
 {'eval_loss': -0.5933931469917297, 'eval_roc_auc': 0.4903753052117538, 'eval_runtime': 4.7633, 'eval_samples_per_second': 183.068, 'eval_steps_per_second': 5.878}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 43%|████▎     | 12/28 [00:00<00:01, 15.10it/s]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 50%|█████     | 14/28 [00:00<00:00, 14.83it/s]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 57%|█████▋    | 16/28 [00:01<00:00, 14.72it/s]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 64%|██████▍   | 18/28 [00:01<00:00, 14.65it/s]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 71%|███████▏  | 20/28 [00:01<00:00, 14.52it/s]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 79%|███████▊  | 22/28 [00:01<00:00, 14.51it/s]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 86%|████████▌ | 24/28 [00:01<00:00, 14.51it/s]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 93%|█████████▎| 26/28 [00:01<00:00, 14.50it/s]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
100%|██████████| 28/28 [00:01<00:00, 15.05it/s]
02/24/2024 17:40:12 - INFO - __main__ - ***** Running training *****
02/24/2024 17:40:12 - INFO - __main__ -   Num examples = 29,783
02/24/2024 17:40:12 - INFO - __main__ -   Num Epochs = 5
02/24/2024 17:40:12 - INFO - __main__ -   Instantaneous batch size per device = 32
02/24/2024 17:40:12 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 32
02/24/2024 17:40:12 - INFO - __main__ -   Gradient Accumulation steps = 1
02/24/2024 17:40:12 - INFO - __main__ -   Total optimization steps = 4,655
02/24/2024 17:40:12 - INFO - __main__ -   Number of trainable parameters = 12,288
  0%|          | 0/4655 [00:00<?, ?it/s]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  0%|          | 1/4655 [00:00<21:33,  3.60it/s]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                      GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 21%|██▏       | 6/28 [00:00<00:01, 16.78it/s]
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  0%|          | 1/4655 [00:02<21:33,  3.60it/sGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  0%|          | 2/4655 [00:02<1:42:58,  1.33s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                      GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 21%|██▏       | 6/28 [00:00<00:01, 16.73it/s]
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  0%|          | 2/4655 [00:04<1:42:58,  1.33s/GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  0%|          | 3/4655 [00:04<2:09:12,  1.67s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                      GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 21%|██▏       | 6/28 [00:00<00:01, 16.73it/s]
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  0%|          | 3/4655 [00:06<2:09:12,  1.67s/GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  0%|          | 4/4655 [00:06<2:21:32,  1.83s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                      GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5907226800918579, 'eval_roc_auc': 0.49034636271785803, 'eval_runtime': 1.9456, 'eval_samples_per_second': 448.195, 'eval_steps_per_second': 14.392, 'epoch': 0.0}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  0%|          | 4/4655 [00:08<2:21:32,  1.83s/GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  0%|          | 5/4655 [00:08<2:29:08,  1.92s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                      GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 11%|█         | 3/28 [00:00<00:01, 21.39it/s]
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  0%|          | 5/4655 [00:10<2:29:08,  1.92s/GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  0%|          | 6/4655 [00:10<2:34:12,  1.99s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                      GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  0%|          | 0/28 [00:00<?, ?it/s]
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5893927216529846, 'eval_roc_auc': 0.4903858297549887, 'eval_runtime': 1.9328, 'eval_samples_per_second': 451.158, 'eval_steps_per_second': 14.487, 'epoch': 0.01}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  0%|          | 6/4655 [00:12<2:34:12,  1.99s/GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  0%|          | 7/4655 [00:12<2:36:35,  2.02s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  0%|          | 0/28 [00:00<?, ?it/s]
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5887293219566345, 'eval_roc_auc': 0.49035425612528416, 'eval_runtime': 1.9369, 'eval_samples_per_second': 450.192, 'eval_steps_per_second': 14.456, 'epoch': 0.01}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  0%|          | 7/4655 [00:14<2:36:35,  2.02s/GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  0%|          | 8/4655 [00:14<2:38:18,  2.04s/it]
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5880637168884277, 'eval_roc_auc': 0.4904016165698408, 'eval_runtime': 1.94, 'eval_samples_per_second': 449.485, 'eval_steps_per_second': 14.433, 'epoch': 0.01}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  0%|          | 8/4655 [00:16<2:38:18,  2.04s/GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  0%|          | 9/4655 [00:18<2:39:32,  2.06s/it]
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5873991250991821, 'eval_roc_auc': 0.4904121411130757, 'eval_runtime': 1.9399, 'eval_samples_per_second': 449.504, 'eval_steps_per_second': 14.434, 'epoch': 0.01}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5867332220077515, 'eval_roc_auc': 0.4904279279279279, 'eval_runtime': 1.9294, 'eval_samples_per_second': 451.961, 'eval_steps_per_second': 14.513, 'epoch': 0.01}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 93%|█████████▎| 26/28 [00:01<00:00, 14.30it/s]
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5860668420791626, 'eval_roc_auc': 0.49044371474278015, 'eval_runtime': 1.9333, 'eval_samples_per_second': 451.047, 'eval_steps_per_second': 14.483, 'epoch': 0.01}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 86%|████████▌ | 24/28 [00:01<00:00, 14.28it/s]
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.585407018661499, 'eval_roc_auc': 0.49041214111307574, 'eval_runtime': 1.9392, 'eval_samples_per_second': 449.661, 'eval_steps_per_second': 14.439, 'epoch': 0.01}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5847530961036682, 'eval_roc_auc': 0.4904174033846931, 'eval_runtime': 1.9484, 'eval_samples_per_second': 447.554, 'eval_steps_per_second': 14.371, 'epoch': 0.01}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 79%|███████▊  | 22/28 [00:01<00:00, 14.25it/s]
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5840984582901001, 'eval_roc_auc': 0.4904384524711627, 'eval_runtime': 1.9504, 'eval_samples_per_second': 447.089, 'eval_steps_per_second': 14.356, 'epoch': 0.02}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 71%|███████▏  | 20/28 [00:01<00:00, 14.24it/s]
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5834425687789917, 'eval_roc_auc': 0.4904595015576324, 'eval_runtime': 1.9496, 'eval_samples_per_second': 447.277, 'eval_steps_per_second': 14.362, 'epoch': 0.02}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 71%|███████▏  | 20/28 [00:01<00:00, 14.22it/s]
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5827857851982117, 'eval_roc_auc': 0.4904489770143976, 'eval_runtime': 1.9536, 'eval_samples_per_second': 446.366, 'eval_steps_per_second': 14.333, 'epoch': 0.02}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 64%|██████▍   | 18/28 [00:01<00:00, 14.30it/s]
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5821321606636047, 'eval_roc_auc': 0.49043319019954534, 'eval_runtime': 1.9563, 'eval_samples_per_second': 445.75, 'eval_steps_per_second': 14.313, 'epoch': 0.02}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 57%|█████▋    | 16/28 [00:01<00:00, 14.36it/s]
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5814819931983948, 'eval_roc_auc': 0.490391092026606, 'eval_runtime': 1.9642, 'eval_samples_per_second': 443.946, 'eval_steps_per_second': 14.255, 'epoch': 0.02}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5808308720588684, 'eval_roc_auc': 0.4904121411130757, 'eval_runtime': 1.9589, 'eval_samples_per_second': 445.15, 'eval_steps_per_second': 14.294, 'epoch': 0.02}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 50%|█████     | 14/28 [00:00<00:00, 14.40it/s]
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5801746249198914, 'eval_roc_auc': 0.4903700429401364, 'eval_runtime': 1.9595, 'eval_samples_per_second': 445.011, 'eval_steps_per_second': 14.289, 'epoch': 0.02}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 43%|████▎     | 12/28 [00:00<00:01, 14.61it/s]
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5795168280601501, 'eval_roc_auc': 0.4903595183969016, 'eval_runtime': 1.9655, 'eval_samples_per_second': 443.651, 'eval_steps_per_second': 14.246, 'epoch': 0.02}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                               GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 36%|███▌      | 10/28 [00:00<00:01, 14.88it/s]
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5798055529594421, 'eval_roc_auc': 0.49034373158204936, 'eval_runtime': 1.9665, 'eval_samples_per_second': 443.423, 'eval_steps_per_second': 14.238, 'epoch': 0.02}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 36%|███▌      | 10/28 [00:00<00:01, 14.88it/s]
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.580061137676239, 'eval_roc_auc': 0.49035425612528416, 'eval_runtime': 1.9705, 'eval_samples_per_second': 442.517, 'eval_steps_per_second': 14.209, 'epoch': 0.02}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 29%|██▊       | 8/28 [00:00<00:01, 15.32it/s]
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5802873969078064, 'eval_roc_auc': 0.4903753052117538, 'eval_runtime': 1.9737, 'eval_samples_per_second': 441.806, 'eval_steps_per_second': 14.186, 'epoch': 0.03}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
                                              GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 21%|██▏       | 6/28 [00:00<00:01, 16.20it/s]
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.580486536026001, 'eval_roc_auc': 0.49037004294013636, 'eval_runtime': 1.9964, 'eval_samples_per_second': 436.788, 'eval_steps_per_second': 14.025, 'epoch': 0.03}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 11%|█         | 3/28 [00:00<00:01, 20.94it/s]padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 11%|█         | 3/28 [00:00<00:01, 20.94it/s]padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5809431672096252, 'eval_roc_auc': 0.4903753052117538, 'eval_runtime': 1.9892, 'eval_samples_per_second': 438.366, 'eval_steps_per_second': 14.076, 'epoch': 0.03}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5810546875, 'eval_roc_auc': 0.490364780668519, 'eval_runtime': 1.9868, 'eval_samples_per_second': 438.904, 'eval_steps_per_second': 14.093, 'epoch': 0.03}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5811485052108765, 'eval_roc_auc': 0.4903753052117539, 'eval_runtime': 1.9893, 'eval_samples_per_second': 438.346, 'eval_steps_per_second': 14.075, 'epoch': 0.03}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5812258720397949, 'eval_roc_auc': 0.4903700429401364, 'eval_runtime': 1.9902, 'eval_samples_per_second': 438.14, 'eval_steps_per_second': 14.069, 'epoch': 0.03}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5812894701957703, 'eval_roc_auc': 0.49036478066851896, 'eval_runtime': 1.9964, 'eval_samples_per_second': 436.792, 'eval_steps_per_second': 14.025, 'epoch': 0.03}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5813395380973816, 'eval_roc_auc': 0.49037530521175376, 'eval_runtime': 2.0168, 'eval_samples_per_second': 432.364, 'eval_steps_per_second': 13.883, 'epoch': 0.04}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.581376314163208, 'eval_roc_auc': 0.49037530521175376, 'eval_runtime': 1.9983, 'eval_samples_per_second': 436.36, 'eval_steps_per_second': 14.012, 'epoch': 0.04}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5814019441604614, 'eval_roc_auc': 0.4903805674833712, 'eval_runtime': 1.9968, 'eval_samples_per_second': 436.69, 'eval_steps_per_second': 14.022, 'epoch': 0.04}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5814171433448792, 'eval_roc_auc': 0.49037793634756244, 'eval_runtime': 2.0008, 'eval_samples_per_second': 435.818, 'eval_steps_per_second': 13.994, 'epoch': 0.04}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5814235806465149, 'eval_roc_auc': 0.4903595183969016, 'eval_runtime': 2.0089, 'eval_samples_per_second': 434.07, 'eval_steps_per_second': 13.938, 'epoch': 0.04}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 11%|█         | 3/28 [00:00<00:01, 20.71it/s]padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 11%|█         | 3/28 [00:00<00:01, 20.71it/s]padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5813920497894287, 'eval_roc_auc': 0.49035951839690156, 'eval_runtime': 2.0066, 'eval_samples_per_second': 434.576, 'eval_steps_per_second': 13.954, 'epoch': 0.04}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5813671350479126, 'eval_roc_auc': 0.49036478066851896, 'eval_runtime': 2.0067, 'eval_samples_per_second': 434.539, 'eval_steps_per_second': 13.953, 'epoch': 0.04}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5813360810279846, 'eval_roc_auc': 0.4903595183969016, 'eval_runtime': 2.0056, 'eval_samples_per_second': 434.785, 'eval_steps_per_second': 13.961, 'epoch': 0.05}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.581299901008606, 'eval_roc_auc': 0.4903700429401364, 'eval_runtime': 2.0067, 'eval_samples_per_second': 434.55, 'eval_steps_per_second': 13.953, 'epoch': 0.05}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5812581181526184, 'eval_roc_auc': 0.49035951839690156, 'eval_runtime': 2.0065, 'eval_samples_per_second': 434.594, 'eval_steps_per_second': 13.955, 'epoch': 0.05}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5812113285064697, 'eval_roc_auc': 0.4903516249894755, 'eval_runtime': 2.0225, 'eval_samples_per_second': 431.151, 'eval_steps_per_second': 13.844, 'epoch': 0.05}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5811599493026733, 'eval_roc_auc': 0.49035425612528416, 'eval_runtime': 2.0079, 'eval_samples_per_second': 434.282, 'eval_steps_per_second': 13.945, 'epoch': 0.05}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5811034440994263, 'eval_roc_auc': 0.49034899385366676, 'eval_runtime': 2.0111, 'eval_samples_per_second': 433.583, 'eval_steps_per_second': 13.922, 'epoch': 0.05}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5810436010360718, 'eval_roc_auc': 0.49035688726109294, 'eval_runtime': 2.0104, 'eval_samples_per_second': 433.754, 'eval_steps_per_second': 13.928, 'epoch': 0.05}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5809796452522278, 'eval_roc_auc': 0.490364780668519, 'eval_runtime': 2.0109, 'eval_samples_per_second': 433.637, 'eval_steps_per_second': 13.924, 'epoch': 0.05}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5809118747711182, 'eval_roc_auc': 0.4903489938536667, 'eval_runtime': 2.012, 'eval_samples_per_second': 433.398, 'eval_steps_per_second': 13.916, 'epoch': 0.05}
 11%|█         | 3/28 [00:00<00:01, 20.68it/s]padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 11%|█         | 3/28 [00:00<00:01, 20.68it/s]padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5807694792747498, 'eval_roc_auc': 0.4903174202239623, 'eval_runtime': 2.0104, 'eval_samples_per_second': 433.751, 'eval_steps_per_second': 13.928, 'epoch': 0.06}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5806934237480164, 'eval_roc_auc': 0.49029637113749264, 'eval_runtime': 2.0168, 'eval_samples_per_second': 432.37, 'eval_steps_per_second': 13.883, 'epoch': 0.06}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5806146860122681, 'eval_roc_auc': 0.4902937400016839, 'eval_runtime': 2.0156, 'eval_samples_per_second': 432.626, 'eval_steps_per_second': 13.892, 'epoch': 0.06}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.580532968044281, 'eval_roc_auc': 0.4902911088658753, 'eval_runtime': 2.0182, 'eval_samples_per_second': 432.077, 'eval_steps_per_second': 13.874, 'epoch': 0.06}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  1%|          | 56/4655 [01:59<2:46:50,  2.18sGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  1%|          | 56/4655 [01:59<2:46:50,  2.18sGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5803641080856323, 'eval_roc_auc': 0.49031215795234484, 'eval_runtime': 2.0146, 'eval_samples_per_second': 432.839, 'eval_steps_per_second': 13.899, 'epoch': 0.06}
  1%|          | 56/4655 [01:59<2:46:50,  2.18sGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5802767872810364, 'eval_roc_auc': 0.49033320703881456, 'eval_runtime': 2.016, 'eval_samples_per_second': 432.549, 'eval_steps_per_second': 13.889, 'epoch': 0.06}
  1%|          | 56/4655 [01:59<2:46:50,  2.18sGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5801882743835449, 'eval_roc_auc': 0.49032794476719715, 'eval_runtime': 2.019, 'eval_samples_per_second': 431.891, 'eval_steps_per_second': 13.868, 'epoch': 0.06}
  1%|          | 56/4655 [01:59<2:46:50,  2.18sGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5800981521606445, 'eval_roc_auc': 0.49032794476719715, 'eval_runtime': 2.0436, 'eval_samples_per_second': 426.698, 'eval_steps_per_second': 13.701, 'epoch': 0.06}
  1%|          | 56/4655 [01:59<2:46:50,  2.18sGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5799127221107483, 'eval_roc_auc': 0.4903226824955797, 'eval_runtime': 2.0191, 'eval_samples_per_second': 431.869, 'eval_steps_per_second': 13.867, 'epoch': 0.07}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5796234607696533, 'eval_roc_auc': 0.49029637113749264, 'eval_runtime': 2.0593, 'eval_samples_per_second': 423.453, 'eval_steps_per_second': 13.597, 'epoch': 0.07}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5795224905014038, 'eval_roc_auc': 0.4903174202239623, 'eval_runtime': 2.0238, 'eval_samples_per_second': 430.87, 'eval_steps_per_second': 13.835, 'epoch': 0.07}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5794199705123901, 'eval_roc_auc': 0.49031215795234484, 'eval_runtime': 2.0275, 'eval_samples_per_second': 430.095, 'eval_steps_per_second': 13.81, 'epoch': 0.07}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`
  1%|▏         | 69/4655 [02:26<2:47:20,  2.19s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  1%|▏         | 69/4655 [02:26<2:47:20,  2.19s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5791052579879761, 'eval_roc_auc': 0.49024901069293597, 'eval_runtime': 2.025, 'eval_samples_per_second': 430.627, 'eval_steps_per_second': 13.827, 'epoch': 0.08}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ds.`
{'eval_loss': -0.5788883566856384, 'eval_roc_auc': 0.49024901069293597, 'eval_runtime': 2.0273, 'eval_samples_per_second': 430.122, 'eval_steps_per_second': 13.811, 'epoch': 0.08}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ds.`
{'eval_loss': -0.5787786841392517, 'eval_roc_auc': 0.49028058432264043, 'eval_runtime': 2.0302, 'eval_samples_per_second': 429.51, 'eval_steps_per_second': 13.792, 'epoch': 0.08}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`ds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`ds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`ds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`ds.`
{'eval_loss': -0.578330934047699, 'eval_roc_auc': 0.4902384861497011, 'eval_runtime': 2.0268, 'eval_samples_per_second': 430.24, 'eval_steps_per_second': 13.815, 'epoch': 0.08}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`ds.`
{'eval_loss': -0.5782168507575989, 'eval_roc_auc': 0.4902279616064663, 'eval_runtime': 2.0312, 'eval_samples_per_second': 429.31, 'eval_steps_per_second': 13.785, 'epoch': 0.08}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`ds.`
{'eval_loss': -0.578101396560669, 'eval_roc_auc': 0.4902279616064662, 'eval_runtime': 2.032, 'eval_samples_per_second': 429.133, 'eval_steps_per_second': 13.779, 'epoch': 0.08}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`ds.`
  2%|▏         | 81/4655 [02:52<2:47:08,  2.19s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  2%|▏         | 81/4655 [02:52<2:47:08,  2.19s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  2%|▏         | 81/4655 [02:52<2:47:08,  2.19sGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ds.`
  2%|▏         | 81/4655 [02:52<2:47:08,  2.19sGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`ds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`ds.`
{'eval_loss': -0.577632486820221, 'eval_roc_auc': 0.4902174370632315, 'eval_runtime': 2.028, 'eval_samples_per_second': 429.978, 'eval_steps_per_second': 13.807, 'epoch': 0.09}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`ds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`ds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`ds.`
{'eval_loss': -0.5773962140083313, 'eval_roc_auc': 0.4902490106929359, 'eval_runtime': 2.0276, 'eval_samples_per_second': 430.057, 'eval_steps_per_second': 13.809, 'epoch': 0.09}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`ds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``ds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``ds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``ds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``ds.`
{'eval_loss': -0.5770387053489685, 'eval_roc_auc': 0.4902384861497011, 'eval_runtime': 2.0501, 'eval_samples_per_second': 425.354, 'eval_steps_per_second': 13.658, 'epoch': 0.09}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``ds.`
  2%|▏         | 89/4655 [03:12<2:47:28,  2.20sGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ds.`
  2%|▏         | 89/4655 [03:12<2:47:28,  2.20sGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ds.`
{'eval_loss': -0.5767959356307983, 'eval_roc_auc': 0.490230592742275, 'eval_runtime': 2.0296, 'eval_samples_per_second': 429.639, 'eval_steps_per_second': 13.796, 'epoch': 0.1}
  2%|▏         | 89/4655 [03:12<2:47:28,  2.20sGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ds.`
{'eval_loss': -0.5766728520393372, 'eval_roc_auc': 0.49022796160646626, 'eval_runtime': 2.0283, 'eval_samples_per_second': 429.924, 'eval_steps_per_second': 13.805, 'epoch': 0.1}
  2%|▏         | 89/4655 [03:12<2:47:28,  2.20sGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`ds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`ds.`
{'eval_loss': -0.5764243602752686, 'eval_roc_auc': 0.4902174370632315, 'eval_runtime': 2.0308, 'eval_samples_per_second': 429.383, 'eval_steps_per_second': 13.788, 'epoch': 0.1}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`ds.`
{'eval_loss': -0.576299250125885, 'eval_roc_auc': 0.49025953523617083, 'eval_runtime': 2.0285, 'eval_samples_per_second': 429.875, 'eval_steps_per_second': 13.803, 'epoch': 0.1}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ds.`
{'eval_loss': -0.5761741399765015, 'eval_roc_auc': 0.4902595352361708, 'eval_runtime': 2.0291, 'eval_samples_per_second': 429.74, 'eval_steps_per_second': 13.799, 'epoch': 0.1}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`ds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`ds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``ds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``ds.`
{'eval_loss': -0.5757937431335449, 'eval_roc_auc': 0.490275322051023, 'eval_runtime': 2.0329, 'eval_samples_per_second': 428.94, 'eval_steps_per_second': 13.773, 'epoch': 0.11}
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``ds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``ds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``ds.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`embeds.``ds.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`embeds.``ds.`
  2%|▏         | 101/4655 [03:38<2:46:21,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ds.`
  2%|▏         | 101/4655 [03:38<2:46:21,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ds.`
{'eval_loss': -0.5752748250961304, 'eval_roc_auc': 0.4902647975077882, 'eval_runtime': 2.0528, 'eval_samples_per_second': 424.775, 'eval_steps_per_second': 13.64, 'epoch': 0.11}
  2%|▏         | 101/4655 [03:38<2:46:21,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`ds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`ds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ds.`
{'eval_loss': -0.5748783946037292, 'eval_roc_auc': 0.4902279616064662, 'eval_runtime': 2.0319, 'eval_samples_per_second': 429.148, 'eval_steps_per_second': 13.78, 'epoch': 0.11}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``ds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``ds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``ds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``ds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``ds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``ds.`
  2%|▏         | 110/4655 [03:56<2:46:22,  2.20s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  2%|▏         | 110/4655 [03:56<2:46:22,  2.20s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5740688443183899, 'eval_roc_auc': 0.49023848614970117, 'eval_runtime': 2.0313, 'eval_samples_per_second': 429.272, 'eval_steps_per_second': 13.784, 'epoch': 0.12}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5737938284873962, 'eval_roc_auc': 0.4902384861497011, 'eval_runtime': 2.0313, 'eval_samples_per_second': 429.288, 'eval_steps_per_second': 13.784, 'epoch': 0.12}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5735175609588623, 'eval_roc_auc': 0.49022269933484885, 'eval_runtime': 2.0582, 'eval_samples_per_second': 423.671, 'eval_steps_per_second': 13.604, 'epoch': 0.12}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5732389092445374, 'eval_roc_auc': 0.49022269933484885, 'eval_runtime': 2.0325, 'eval_samples_per_second': 429.026, 'eval_steps_per_second': 13.776, 'epoch': 0.13}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`embeds.``eds.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`embeds.``eds.`
  3%|▎         | 121/4655 [04:22<2:45:47,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
  3%|▎         | 121/4655 [04:22<2:45:47,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5725311636924744, 'eval_roc_auc': 0.4902174370632315, 'eval_runtime': 2.0338, 'eval_samples_per_second': 428.757, 'eval_steps_per_second': 13.767, 'epoch': 0.13}
  3%|▎         | 121/4655 [04:22<2:45:47,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.572246253490448, 'eval_roc_auc': 0.4902595352361707, 'eval_runtime': 2.0337, 'eval_samples_per_second': 428.766, 'eval_steps_per_second': 13.768, 'epoch': 0.13}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5721029043197632, 'eval_roc_auc': 0.4902437484213185, 'eval_runtime': 2.0317, 'eval_samples_per_second': 429.19, 'eval_steps_per_second': 13.781, 'epoch': 0.13}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.571814775466919, 'eval_roc_auc': 0.4902279616064663, 'eval_runtime': 2.0356, 'eval_samples_per_second': 428.381, 'eval_steps_per_second': 13.755, 'epoch': 0.14}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5715263485908508, 'eval_roc_auc': 0.49024374842131846, 'eval_runtime': 2.0545, 'eval_samples_per_second': 424.444, 'eval_steps_per_second': 13.629, 'epoch': 0.14}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5713822841644287, 'eval_roc_auc': 0.4902490106929359, 'eval_runtime': 2.0303, 'eval_samples_per_second': 429.494, 'eval_steps_per_second': 13.791, 'epoch': 0.14}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
  3%|▎         | 133/4655 [04:46<2:45:32,  2.20s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  3%|▎         | 133/4655 [04:46<2:45:32,  2.20s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5706470608711243, 'eval_roc_auc': 0.49022269933484885, 'eval_runtime': 2.0315, 'eval_samples_per_second': 429.236, 'eval_steps_per_second': 13.783, 'epoch': 0.15}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5704970955848694, 'eval_roc_auc': 0.4902437484213185, 'eval_runtime': 2.052, 'eval_samples_per_second': 424.96, 'eval_steps_per_second': 13.645, 'epoch': 0.15}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5703481435775757, 'eval_roc_auc': 0.49022533047065764, 'eval_runtime': 2.033, 'eval_samples_per_second': 428.926, 'eval_steps_per_second': 13.773, 'epoch': 0.15}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
{'eval_loss': -0.5698976516723633, 'eval_roc_auc': 0.49021217479161405, 'eval_runtime': 2.0332, 'eval_samples_per_second': 428.88, 'eval_steps_per_second': 13.771, 'epoch': 0.15}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
  3%|▎         | 141/4655 [05:06<2:45:11,  2.20GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
  3%|▎         | 141/4655 [05:06<2:45:11,  2.20GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5695950388908386, 'eval_roc_auc': 0.49022269933484885, 'eval_runtime': 2.0324, 'eval_samples_per_second': 429.049, 'eval_steps_per_second': 13.777, 'epoch': 0.15}
  3%|▎         | 141/4655 [05:06<2:45:11,  2.20GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5704331398010254, 'eval_roc_auc': 0.49022796160646626, 'eval_runtime': 2.0313, 'eval_samples_per_second': 429.289, 'eval_steps_per_second': 13.785, 'epoch': 0.15}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5710755586624146, 'eval_roc_auc': 0.4902542729645534, 'eval_runtime': 2.0322, 'eval_samples_per_second': 429.097, 'eval_steps_per_second': 13.778, 'epoch': 0.16}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5713348984718323, 'eval_roc_auc': 0.49025427296455326, 'eval_runtime': 2.0316, 'eval_samples_per_second': 429.219, 'eval_steps_per_second': 13.782, 'epoch': 0.16}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5715572237968445, 'eval_roc_auc': 0.4902437484213185, 'eval_runtime': 2.0311, 'eval_samples_per_second': 429.318, 'eval_steps_per_second': 13.785, 'epoch': 0.16}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5719053745269775, 'eval_roc_auc': 0.4902858465942578, 'eval_runtime': 2.0321, 'eval_samples_per_second': 429.103, 'eval_steps_per_second': 13.779, 'epoch': 0.16}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
  3%|▎         | 153/4655 [05:30<2:44:36,  2.19s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  3%|▎         | 153/4655 [05:30<2:44:36,  2.19s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5722966194152832, 'eval_roc_auc': 0.49024374842131857, 'eval_runtime': 2.0313, 'eval_samples_per_second': 429.286, 'eval_steps_per_second': 13.784, 'epoch': 0.17}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.572376012802124, 'eval_roc_auc': 0.4902437484213185, 'eval_runtime': 2.0349, 'eval_samples_per_second': 428.532, 'eval_steps_per_second': 13.76, 'epoch': 0.17}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5723937749862671, 'eval_roc_auc': 0.4902542729645533, 'eval_runtime': 2.049, 'eval_samples_per_second': 425.574, 'eval_steps_per_second': 13.665, 'epoch': 0.17}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
{'eval_loss': -0.5723453760147095, 'eval_roc_auc': 0.4902700597794056, 'eval_runtime': 2.0316, 'eval_samples_per_second': 429.214, 'eval_steps_per_second': 13.782, 'epoch': 0.17}
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5721496939659119, 'eval_roc_auc': 0.4902647975077882, 'eval_runtime': 2.0344, 'eval_samples_per_second': 428.62, 'eval_steps_per_second': 13.763, 'epoch': 0.18}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5720142722129822, 'eval_roc_auc': 0.4902647975077882, 'eval_runtime': 2.0312, 'eval_samples_per_second': 429.298, 'eval_steps_per_second': 13.785, 'epoch': 0.18}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5719389319419861, 'eval_roc_auc': 0.4902700597794056, 'eval_runtime': 2.0374, 'eval_samples_per_second': 428.004, 'eval_steps_per_second': 13.743, 'epoch': 0.18}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
  4%|▎         | 173/4655 [06:14<2:44:12,  2.20s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  4%|▎         | 173/4655 [06:14<2:44:12,  2.20s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5712963342666626, 'eval_roc_auc': 0.49025427296455326, 'eval_runtime': 2.0364, 'eval_samples_per_second': 428.209, 'eval_steps_per_second': 13.75, 'epoch': 0.19}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5711928606033325, 'eval_roc_auc': 0.4902595352361707, 'eval_runtime': 2.0312, 'eval_samples_per_second': 429.298, 'eval_steps_per_second': 13.785, 'epoch': 0.19}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5709797143936157, 'eval_roc_auc': 0.4902542729645534, 'eval_runtime': 2.0285, 'eval_samples_per_second': 429.865, 'eval_steps_per_second': 13.803, 'epoch': 0.19}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5708703994750977, 'eval_roc_auc': 0.4902542729645533, 'eval_runtime': 2.0304, 'eval_samples_per_second': 429.473, 'eval_steps_per_second': 13.79, 'epoch': 0.19}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5706440806388855, 'eval_roc_auc': 0.4902542729645533, 'eval_runtime': 2.0326, 'eval_samples_per_second': 429.013, 'eval_steps_per_second': 13.776, 'epoch': 0.19}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5705281496047974, 'eval_roc_auc': 0.4902542729645534, 'eval_runtime': 2.0391, 'eval_samples_per_second': 427.639, 'eval_steps_per_second': 13.732, 'epoch': 0.2}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5704100131988525, 'eval_roc_auc': 0.49027005977940563, 'eval_runtime': 2.0306, 'eval_samples_per_second': 429.427, 'eval_steps_per_second': 13.789, 'epoch': 0.2}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
  4%|▍         | 184/4655 [06:40<2:43:33,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
  4%|▍         | 184/4655 [06:40<2:43:33,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5701688528060913, 'eval_roc_auc': 0.4902542729645534, 'eval_runtime': 2.0307, 'eval_samples_per_second': 429.417, 'eval_steps_per_second': 13.789, 'epoch': 0.2}
  4%|▍         | 184/4655 [06:40<2:43:33,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5699290037155151, 'eval_roc_auc': 0.49021743706323145, 'eval_runtime': 2.0336, 'eval_samples_per_second': 428.79, 'eval_steps_per_second': 13.768, 'epoch': 0.2}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`embeds.``eds.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`embeds.``eds.`
{'eval_loss': -0.5690591931343079, 'eval_roc_auc': 0.49023585501389244, 'eval_runtime': 2.0351, 'eval_samples_per_second': 428.487, 'eval_steps_per_second': 13.759, 'epoch': 0.21}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`embeds.``eds.`
{'eval_loss': -0.5689340829849243, 'eval_roc_auc': 0.49022796160646626, 'eval_runtime': 2.0331, 'eval_samples_per_second': 428.892, 'eval_steps_per_second': 13.772, 'epoch': 0.21}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`embeds.``eds.`
{'eval_loss': -0.568808376789093, 'eval_roc_auc': 0.4902384861497011, 'eval_runtime': 2.0306, 'eval_samples_per_second': 429.42, 'eval_steps_per_second': 13.789, 'epoch': 0.21}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`embeds.``eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5684271454811096, 'eval_roc_auc': 0.4902279616064663, 'eval_runtime': 2.0335, 'eval_samples_per_second': 428.808, 'eval_steps_per_second': 13.769, 'epoch': 0.21}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.56829833984375, 'eval_roc_auc': 0.4902332238780837, 'eval_runtime': 2.0347, 'eval_samples_per_second': 428.564, 'eval_steps_per_second': 13.761, 'epoch': 0.21}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5680382251739502, 'eval_roc_auc': 0.4902200681990402, 'eval_runtime': 2.0325, 'eval_samples_per_second': 429.02, 'eval_steps_per_second': 13.776, 'epoch': 0.22}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
  4%|▍         | 205/4655 [07:24<2:42:47,  2.19s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  4%|▍         | 205/4655 [07:24<2:42:47,  2.19s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5673843622207642, 'eval_roc_auc': 0.4902384861497011, 'eval_runtime': 2.0306, 'eval_samples_per_second': 429.43, 'eval_steps_per_second': 13.789, 'epoch': 0.22}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5672529935836792, 'eval_roc_auc': 0.4902490106929359, 'eval_runtime': 2.0314, 'eval_samples_per_second': 429.255, 'eval_steps_per_second': 13.783, 'epoch': 0.22}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5667274594306946, 'eval_roc_auc': 0.4902542729645534, 'eval_runtime': 2.0358, 'eval_samples_per_second': 428.338, 'eval_steps_per_second': 13.754, 'epoch': 0.23}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
{'eval_loss': -0.5664600729942322, 'eval_roc_auc': 0.4902490106929359, 'eval_runtime': 2.033, 'eval_samples_per_second': 428.914, 'eval_steps_per_second': 13.772, 'epoch': 0.23}
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`embeds.``eds.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`embeds.``eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.565919816493988, 'eval_roc_auc': 0.4902490106929359, 'eval_runtime': 2.0329, 'eval_samples_per_second': 428.951, 'eval_steps_per_second': 13.774, 'epoch': 0.23}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5655094385147095, 'eval_roc_auc': 0.4902542729645533, 'eval_runtime': 2.0339, 'eval_samples_per_second': 428.738, 'eval_steps_per_second': 13.767, 'epoch': 0.24}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5653728246688843, 'eval_roc_auc': 0.4902437484213185, 'eval_runtime': 2.0323, 'eval_samples_per_second': 429.071, 'eval_steps_per_second': 13.778, 'epoch': 0.24}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5652369260787964, 'eval_roc_auc': 0.49022796160646626, 'eval_runtime': 2.034, 'eval_samples_per_second': 428.711, 'eval_steps_per_second': 13.766, 'epoch': 0.24}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
  5%|▍         | 225/4655 [08:08<2:42:03,  2.19s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  5%|▍         | 225/4655 [08:08<2:42:03,  2.19s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  5%|▍         | 225/4655 [08:08<2:42:03,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
  5%|▍         | 225/4655 [08:08<2:42:03,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5648285150527954, 'eval_roc_auc': 0.49022269933484885, 'eval_runtime': 2.0293, 'eval_samples_per_second': 429.707, 'eval_steps_per_second': 13.798, 'epoch': 0.24}
  5%|▍         | 225/4655 [08:08<2:42:03,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5645501613616943, 'eval_roc_auc': 0.4902279616064663, 'eval_runtime': 2.0506, 'eval_samples_per_second': 425.251, 'eval_steps_per_second': 13.655, 'epoch': 0.24}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.564410924911499, 'eval_roc_auc': 0.4902542729645534, 'eval_runtime': 2.0294, 'eval_samples_per_second': 429.687, 'eval_steps_per_second': 13.797, 'epoch': 0.25}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
{'eval_loss': -0.5638493895530701, 'eval_roc_auc': 0.49025953523617083, 'eval_runtime': 2.0346, 'eval_samples_per_second': 428.589, 'eval_steps_per_second': 13.762, 'epoch': 0.25}
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
{'eval_loss': -0.563563346862793, 'eval_roc_auc': 0.49027795318683176, 'eval_runtime': 2.0307, 'eval_samples_per_second': 429.415, 'eval_steps_per_second': 13.789, 'epoch': 0.25}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
  5%|▌         | 236/4655 [08:35<2:41:39,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
  5%|▌         | 236/4655 [08:35<2:41:39,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5632770657539368, 'eval_roc_auc': 0.4902647975077882, 'eval_runtime': 2.0366, 'eval_samples_per_second': 428.168, 'eval_steps_per_second': 13.749, 'epoch': 0.25}
  5%|▌         | 236/4655 [08:35<2:41:39,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5631343126296997, 'eval_roc_auc': 0.4902595352361707, 'eval_runtime': 2.0341, 'eval_samples_per_second': 428.7, 'eval_steps_per_second': 13.766, 'epoch': 0.26}
  5%|▌         | 236/4655 [08:35<2:41:39,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5627069473266602, 'eval_roc_auc': 0.4902647975077882, 'eval_runtime': 2.0387, 'eval_samples_per_second': 427.73, 'eval_steps_per_second': 13.734, 'epoch': 0.26}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
  5%|▌         | 245/4655 [08:52<2:41:44,  2.20s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  5%|▌         | 245/4655 [08:52<2:41:44,  2.20s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5618468523025513, 'eval_roc_auc': 0.49021743706323145, 'eval_runtime': 2.03, 'eval_samples_per_second': 429.551, 'eval_steps_per_second': 13.793, 'epoch': 0.27}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5617016553878784, 'eval_roc_auc': 0.4902016502483792, 'eval_runtime': 2.0549, 'eval_samples_per_second': 424.351, 'eval_steps_per_second': 13.626, 'epoch': 0.27}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5614117980003357, 'eval_roc_auc': 0.4902069125199966, 'eval_runtime': 2.0309, 'eval_samples_per_second': 429.365, 'eval_steps_per_second': 13.787, 'epoch': 0.27}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5612663626670837, 'eval_roc_auc': 0.4901963879767618, 'eval_runtime': 2.0329, 'eval_samples_per_second': 428.944, 'eval_steps_per_second': 13.773, 'epoch': 0.27}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
{'eval_loss': -0.5609762072563171, 'eval_roc_auc': 0.49021217479161405, 'eval_runtime': 2.0571, 'eval_samples_per_second': 423.9, 'eval_steps_per_second': 13.611, 'epoch': 0.27}
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`embeds.``eds.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`embeds.``eds.`
  5%|▌         | 256/4655 [09:18<2:41:04,  2.20GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
  5%|▌         | 256/4655 [09:18<2:41:04,  2.20GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5603963732719421, 'eval_roc_auc': 0.4902042813841879, 'eval_runtime': 2.0314, 'eval_samples_per_second': 429.256, 'eval_steps_per_second': 13.783, 'epoch': 0.28}
  5%|▌         | 256/4655 [09:18<2:41:04,  2.20GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.560107409954071, 'eval_roc_auc': 0.4901911257051444, 'eval_runtime': 2.0283, 'eval_samples_per_second': 429.915, 'eval_steps_per_second': 13.805, 'epoch': 0.28}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.559962272644043, 'eval_roc_auc': 0.4901937568409531, 'eval_runtime': 2.0294, 'eval_samples_per_second': 429.687, 'eval_steps_per_second': 13.797, 'epoch': 0.28}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5596710443496704, 'eval_roc_auc': 0.49013324071735287, 'eval_runtime': 2.0302, 'eval_samples_per_second': 429.524, 'eval_steps_per_second': 13.792, 'epoch': 0.28}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
  6%|▌         | 268/4655 [09:43<2:40:39,  2.20s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  6%|▌         | 268/4655 [09:43<2:40:39,  2.20s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5586252808570862, 'eval_roc_auc': 0.490096404816031, 'eval_runtime': 2.0301, 'eval_samples_per_second': 429.539, 'eval_steps_per_second': 13.793, 'epoch': 0.29}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5580264329910278, 'eval_roc_auc': 0.4900753557295613, 'eval_runtime': 2.0303, 'eval_samples_per_second': 429.503, 'eval_steps_per_second': 13.791, 'epoch': 0.29}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5578761696815491, 'eval_roc_auc': 0.49007009345794394, 'eval_runtime': 2.0279, 'eval_samples_per_second': 429.998, 'eval_steps_per_second': 13.807, 'epoch': 0.29}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5577261447906494, 'eval_roc_auc': 0.4900648311863265, 'eval_runtime': 2.0315, 'eval_samples_per_second': 429.243, 'eval_steps_per_second': 13.783, 'epoch': 0.3}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
  6%|▌         | 277/4655 [10:03<2:39:56,  2.19s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  6%|▌         | 277/4655 [10:03<2:39:56,  2.19s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  6%|▌         | 277/4655 [10:03<2:39:56,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
  6%|▌         | 277/4655 [10:03<2:39:56,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5572753548622131, 'eval_roc_auc': 0.49007535572956135, 'eval_runtime': 2.0309, 'eval_samples_per_second': 429.373, 'eval_steps_per_second': 13.787, 'epoch': 0.3}
  6%|▌         | 277/4655 [10:03<2:39:56,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5571221709251404, 'eval_roc_auc': 0.49005956891470914, 'eval_runtime': 2.0465, 'eval_samples_per_second': 426.092, 'eval_steps_per_second': 13.682, 'epoch': 0.3}
  6%|▌         | 277/4655 [10:03<2:39:56,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.556969165802002, 'eval_roc_auc': 0.49006746232213527, 'eval_runtime': 2.0525, 'eval_samples_per_second': 424.853, 'eval_steps_per_second': 13.642, 'epoch': 0.3}
  6%|▌         | 277/4655 [10:03<2:39:56,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.55666184425354, 'eval_roc_auc': 0.4900911425444136, 'eval_runtime': 2.0311, 'eval_samples_per_second': 429.325, 'eval_steps_per_second': 13.786, 'epoch': 0.3}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5565069913864136, 'eval_roc_auc': 0.4901016670876484, 'eval_runtime': 2.0345, 'eval_samples_per_second': 428.607, 'eval_steps_per_second': 13.763, 'epoch': 0.3}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
{'eval_loss': -0.5561965703964233, 'eval_roc_auc': 0.49010166708764835, 'eval_runtime': 2.0342, 'eval_samples_per_second': 428.66, 'eval_steps_per_second': 13.764, 'epoch': 0.31}
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`embeds.``eds.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`embeds.``eds.`
  6%|▌         | 288/4655 [10:29<2:39:48,  2.20GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
  6%|▌         | 288/4655 [10:29<2:39:48,  2.20GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5555686354637146, 'eval_roc_auc': 0.49012534730992674, 'eval_runtime': 2.0291, 'eval_samples_per_second': 429.755, 'eval_steps_per_second': 13.799, 'epoch': 0.31}
  6%|▌         | 288/4655 [10:29<2:39:48,  2.20GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5552561283111572, 'eval_roc_auc': 0.49011219163088315, 'eval_runtime': 2.0289, 'eval_samples_per_second': 429.8, 'eval_steps_per_second': 13.801, 'epoch': 0.31}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5550999045372009, 'eval_roc_auc': 0.49009114254441355, 'eval_runtime': 2.0294, 'eval_samples_per_second': 429.685, 'eval_steps_per_second': 13.797, 'epoch': 0.31}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5547850131988525, 'eval_roc_auc': 0.4901069293592658, 'eval_runtime': 2.0516, 'eval_samples_per_second': 425.031, 'eval_steps_per_second': 13.648, 'epoch': 0.32}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5544700026512146, 'eval_roc_auc': 0.49013324071735287, 'eval_runtime': 2.0353, 'eval_samples_per_second': 428.443, 'eval_steps_per_second': 13.757, 'epoch': 0.32}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5543121695518494, 'eval_roc_auc': 0.490133240717353, 'eval_runtime': 2.0272, 'eval_samples_per_second': 430.151, 'eval_steps_per_second': 13.812, 'epoch': 0.32}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5541529059410095, 'eval_roc_auc': 0.4901121916308832, 'eval_runtime': 2.0327, 'eval_samples_per_second': 428.995, 'eval_steps_per_second': 13.775, 'epoch': 0.32}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5539942383766174, 'eval_roc_auc': 0.49011219163088326, 'eval_runtime': 2.0306, 'eval_samples_per_second': 429.419, 'eval_steps_per_second': 13.789, 'epoch': 0.32}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5536725521087646, 'eval_roc_auc': 0.4901437652605877, 'eval_runtime': 2.0332, 'eval_samples_per_second': 428.891, 'eval_steps_per_second': 13.772, 'epoch': 0.32}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5535107254981995, 'eval_roc_auc': 0.49012271617411807, 'eval_runtime': 2.0333, 'eval_samples_per_second': 428.852, 'eval_steps_per_second': 13.77, 'epoch': 0.32}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5530258417129517, 'eval_roc_auc': 0.49012797844573547, 'eval_runtime': 2.0308, 'eval_samples_per_second': 429.394, 'eval_steps_per_second': 13.788, 'epoch': 0.33}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5528649687767029, 'eval_roc_auc': 0.4901385029889703, 'eval_runtime': 2.0348, 'eval_samples_per_second': 428.533, 'eval_steps_per_second': 13.76, 'epoch': 0.33}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5527041554450989, 'eval_roc_auc': 0.49015955207544, 'eval_runtime': 2.0326, 'eval_samples_per_second': 428.997, 'eval_steps_per_second': 13.775, 'epoch': 0.33}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
  7%|▋         | 309/4655 [11:13<2:39:30,  2.20s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  7%|▋         | 309/4655 [11:13<2:39:30,  2.20s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  7%|▋         | 309/4655 [11:13<2:39:30,  2.20GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
  7%|▋         | 309/4655 [11:13<2:39:30,  2.20GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5522228479385376, 'eval_roc_auc': 0.49014902753220513, 'eval_runtime': 2.0302, 'eval_samples_per_second': 429.506, 'eval_steps_per_second': 13.791, 'epoch': 0.33}
  7%|▋         | 309/4655 [11:13<2:39:30,  2.20GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5520618557929993, 'eval_roc_auc': 0.490122716174118, 'eval_runtime': 2.0329, 'eval_samples_per_second': 428.935, 'eval_steps_per_second': 13.773, 'epoch': 0.33}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5518999099731445, 'eval_roc_auc': 0.4901279784457354, 'eval_runtime': 2.0353, 'eval_samples_per_second': 428.43, 'eval_steps_per_second': 13.757, 'epoch': 0.34}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5515743494033813, 'eval_roc_auc': 0.49011745390250067, 'eval_runtime': 2.0293, 'eval_samples_per_second': 429.713, 'eval_steps_per_second': 13.798, 'epoch': 0.34}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
{'eval_loss': -0.5510854721069336, 'eval_roc_auc': 0.49013324071735287, 'eval_runtime': 2.0303, 'eval_samples_per_second': 429.496, 'eval_steps_per_second': 13.791, 'epoch': 0.34}
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
{'eval_loss': -0.5509209036827087, 'eval_roc_auc': 0.4901279784457354, 'eval_runtime': 2.031, 'eval_samples_per_second': 429.342, 'eval_steps_per_second': 13.786, 'epoch': 0.34}
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`embeds.``eds.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`embeds.``eds.`
  7%|▋         | 320/4655 [11:39<2:38:24,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
  7%|▋         | 320/4655 [11:39<2:38:24,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5500875115394592, 'eval_roc_auc': 0.49013850298897027, 'eval_runtime': 2.0282, 'eval_samples_per_second': 429.933, 'eval_steps_per_second': 13.805, 'epoch': 0.35}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.549748420715332, 'eval_roc_auc': 0.4901306095815442, 'eval_runtime': 2.031, 'eval_samples_per_second': 429.345, 'eval_steps_per_second': 13.786, 'epoch': 0.35}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5495790243148804, 'eval_roc_auc': 0.4901385029889703, 'eval_runtime': 2.029, 'eval_samples_per_second': 429.769, 'eval_steps_per_second': 13.8, 'epoch': 0.35}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5494095087051392, 'eval_roc_auc': 0.49014376526058767, 'eval_runtime': 2.0331, 'eval_samples_per_second': 428.897, 'eval_steps_per_second': 13.772, 'epoch': 0.35}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
  7%|▋         | 329/4655 [11:57<2:38:09,  2.19s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  7%|▋         | 329/4655 [11:57<2:38:09,  2.19s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  7%|▋         | 329/4655 [11:57<2:38:09,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
  7%|▋         | 329/4655 [11:57<2:38:09,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5488956570625305, 'eval_roc_auc': 0.49014376526058767, 'eval_runtime': 2.0309, 'eval_samples_per_second': 429.371, 'eval_steps_per_second': 13.787, 'epoch': 0.35}
  7%|▋         | 329/4655 [11:57<2:38:09,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5487245917320251, 'eval_roc_auc': 0.49014902753220513, 'eval_runtime': 2.0442, 'eval_samples_per_second': 426.581, 'eval_steps_per_second': 13.698, 'epoch': 0.36}
  7%|▋         | 329/4655 [11:57<2:38:09,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5485545992851257, 'eval_roc_auc': 0.49014902753220513, 'eval_runtime': 2.0314, 'eval_samples_per_second': 429.256, 'eval_steps_per_second': 13.783, 'epoch': 0.36}
  7%|▋         | 329/4655 [11:57<2:38:09,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5483862161636353, 'eval_roc_auc': 0.49015955207543993, 'eval_runtime': 2.0304, 'eval_samples_per_second': 429.476, 'eval_steps_per_second': 13.791, 'epoch': 0.36}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5482185482978821, 'eval_roc_auc': 0.49017007661867484, 'eval_runtime': 2.0329, 'eval_samples_per_second': 428.936, 'eval_steps_per_second': 13.773, 'epoch': 0.36}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.548051118850708, 'eval_roc_auc': 0.49016481434705733, 'eval_runtime': 2.0607, 'eval_samples_per_second': 423.166, 'eval_steps_per_second': 13.588, 'epoch': 0.36}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.547883152961731, 'eval_roc_auc': 0.49015955207543993, 'eval_runtime': 2.0316, 'eval_samples_per_second': 429.22, 'eval_steps_per_second': 13.782, 'epoch': 0.36}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
{'eval_loss': -0.5473769903182983, 'eval_roc_auc': 0.49016481434705733, 'eval_runtime': 2.0351, 'eval_samples_per_second': 428.49, 'eval_steps_per_second': 13.759, 'epoch': 0.36}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
  7%|▋         | 340/4655 [12:23<2:37:58,  2.20GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
  7%|▋         | 340/4655 [12:23<2:37:58,  2.20GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5470391511917114, 'eval_roc_auc': 0.49018586343352694, 'eval_runtime': 2.0341, 'eval_samples_per_second': 428.691, 'eval_steps_per_second': 13.765, 'epoch': 0.37}
  7%|▋         | 340/4655 [12:23<2:37:58,  2.20GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5468705296516418, 'eval_roc_auc': 0.4901911257051444, 'eval_runtime': 2.0346, 'eval_samples_per_second': 428.59, 'eval_steps_per_second': 13.762, 'epoch': 0.37}
  7%|▋         | 340/4655 [12:23<2:37:58,  2.20GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5467014908790588, 'eval_roc_auc': 0.49017007661867484, 'eval_runtime': 2.0355, 'eval_samples_per_second': 428.391, 'eval_steps_per_second': 13.756, 'epoch': 0.37}
  7%|▋         | 340/4655 [12:23<2:37:58,  2.20GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5463632941246033, 'eval_roc_auc': 0.490167445482866, 'eval_runtime': 2.0306, 'eval_samples_per_second': 429.424, 'eval_steps_per_second': 13.789, 'epoch': 0.37}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
{'eval_loss': -0.5455089807510376, 'eval_roc_auc': 0.4901753388902922, 'eval_runtime': 2.0308, 'eval_samples_per_second': 429.384, 'eval_steps_per_second': 13.788, 'epoch': 0.38}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
{'eval_loss': -0.5453370809555054, 'eval_roc_auc': 0.49018060116190953, 'eval_runtime': 2.0499, 'eval_samples_per_second': 425.382, 'eval_steps_per_second': 13.659, 'epoch': 0.38}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
{'eval_loss': -0.5451660752296448, 'eval_roc_auc': 0.490185863433527, 'eval_runtime': 2.0412, 'eval_samples_per_second': 427.205, 'eval_steps_per_second': 13.718, 'epoch': 0.38}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5448256134986877, 'eval_roc_auc': 0.4901727077544834, 'eval_runtime': 2.0322, 'eval_samples_per_second': 429.096, 'eval_steps_per_second': 13.778, 'epoch': 0.38}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5462913513183594, 'eval_roc_auc': 0.49017007661867473, 'eval_runtime': 2.0372, 'eval_samples_per_second': 428.037, 'eval_steps_per_second': 13.744, 'epoch': 0.38}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5466604232788086, 'eval_roc_auc': 0.49018060116190953, 'eval_runtime': 2.0347, 'eval_samples_per_second': 428.562, 'eval_steps_per_second': 13.761, 'epoch': 0.38}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5469797253608704, 'eval_roc_auc': 0.4901806011619096, 'eval_runtime': 2.0336, 'eval_samples_per_second': 428.803, 'eval_steps_per_second': 13.769, 'epoch': 0.39}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
  8%|▊         | 361/4655 [13:07<2:37:03,  2.19s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  8%|▊         | 361/4655 [13:07<2:37:03,  2.19s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5478411316871643, 'eval_roc_auc': 0.490185863433527, 'eval_runtime': 2.0297, 'eval_samples_per_second': 429.617, 'eval_steps_per_second': 13.795, 'epoch': 0.39}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5479720830917358, 'eval_roc_auc': 0.4902174370632315, 'eval_runtime': 2.0395, 'eval_samples_per_second': 427.555, 'eval_steps_per_second': 13.729, 'epoch': 0.39}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5480743050575256, 'eval_roc_auc': 0.4902200681990402, 'eval_runtime': 2.0336, 'eval_samples_per_second': 428.801, 'eval_steps_per_second': 13.769, 'epoch': 0.39}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
{'eval_loss': -0.5482658743858337, 'eval_roc_auc': 0.4902069125199966, 'eval_runtime': 2.032, 'eval_samples_per_second': 429.13, 'eval_steps_per_second': 13.779, 'epoch': 0.4}
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`embeds.``eds.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`embeds.``eds.`
  8%|▊         | 372/4655 [13:33<2:37:13,  2.20GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
  8%|▊         | 372/4655 [13:33<2:37:13,  2.20GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5481479167938232, 'eval_roc_auc': 0.4902226993348489, 'eval_runtime': 2.0297, 'eval_samples_per_second': 429.611, 'eval_steps_per_second': 13.795, 'epoch': 0.4}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5480894446372986, 'eval_roc_auc': 0.49023322387808377, 'eval_runtime': 2.0317, 'eval_samples_per_second': 429.189, 'eval_steps_per_second': 13.781, 'epoch': 0.4}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5478679537773132, 'eval_roc_auc': 0.49023322387808366, 'eval_runtime': 2.0299, 'eval_samples_per_second': 429.582, 'eval_steps_per_second': 13.794, 'epoch': 0.41}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
  8%|▊         | 381/4655 [13:51<2:36:25,  2.20s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  8%|▊         | 381/4655 [13:51<2:36:25,  2.20s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5474828481674194, 'eval_roc_auc': 0.4902226993348489, 'eval_runtime': 2.0338, 'eval_samples_per_second': 428.744, 'eval_steps_per_second': 13.767, 'epoch': 0.41}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5472636818885803, 'eval_roc_auc': 0.4902148059274227, 'eval_runtime': 2.0308, 'eval_samples_per_second': 429.389, 'eval_steps_per_second': 13.788, 'epoch': 0.41}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5471497178077698, 'eval_roc_auc': 0.4902226993348489, 'eval_runtime': 2.0303, 'eval_samples_per_second': 429.484, 'eval_steps_per_second': 13.791, 'epoch': 0.41}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.547032356262207, 'eval_roc_auc': 0.4902174370632315, 'eval_runtime': 2.0304, 'eval_samples_per_second': 429.465, 'eval_steps_per_second': 13.79, 'epoch': 0.41}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5466656684875488, 'eval_roc_auc': 0.4902148059274228, 'eval_runtime': 2.0329, 'eval_samples_per_second': 428.953, 'eval_steps_per_second': 13.774, 'epoch': 0.42}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5465393662452698, 'eval_roc_auc': 0.4902069125199966, 'eval_runtime': 2.0567, 'eval_samples_per_second': 423.988, 'eval_steps_per_second': 13.614, 'epoch': 0.42}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5464106202125549, 'eval_roc_auc': 0.49020165024837925, 'eval_runtime': 2.0495, 'eval_samples_per_second': 425.463, 'eval_steps_per_second': 13.662, 'epoch': 0.42}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
  8%|▊         | 393/4655 [14:17<2:36:22,  2.20s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  8%|▊         | 393/4655 [14:17<2:36:22,  2.20s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  8%|▊         | 393/4655 [14:17<2:36:22,  2.20GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
  8%|▊         | 393/4655 [14:17<2:36:22,  2.20GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5460080504417419, 'eval_roc_auc': 0.4901806011619096, 'eval_runtime': 2.0319, 'eval_samples_per_second': 429.159, 'eval_steps_per_second': 13.78, 'epoch': 0.42}
  8%|▊         | 393/4655 [14:17<2:36:22,  2.20GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.545733630657196, 'eval_roc_auc': 0.4901963879767618, 'eval_runtime': 2.0283, 'eval_samples_per_second': 429.914, 'eval_steps_per_second': 13.805, 'epoch': 0.43}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.545455813407898, 'eval_roc_auc': 0.49018060116190953, 'eval_runtime': 2.032, 'eval_samples_per_second': 429.128, 'eval_steps_per_second': 13.779, 'epoch': 0.43}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
{'eval_loss': -0.5450273752212524, 'eval_roc_auc': 0.49019638797676185, 'eval_runtime': 2.0327, 'eval_samples_per_second': 428.988, 'eval_steps_per_second': 13.775, 'epoch': 0.43}
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect GGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5445865392684937, 'eval_roc_auc': 0.4902279616064663, 'eval_runtime': 2.0539, 'eval_samples_per_second': 424.548, 'eval_steps_per_second': 13.632, 'epoch': 0.43}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5442885160446167, 'eval_roc_auc': 0.4902174370632315, 'eval_runtime': 2.0277, 'eval_samples_per_second': 430.035, 'eval_steps_per_second': 13.808, 'epoch': 0.44}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5441379547119141, 'eval_roc_auc': 0.4902279616064663, 'eval_runtime': 2.03, 'eval_samples_per_second': 429.567, 'eval_steps_per_second': 13.793, 'epoch': 0.44}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5439878702163696, 'eval_roc_auc': 0.49021743706323145, 'eval_runtime': 2.0327, 'eval_samples_per_second': 428.983, 'eval_steps_per_second': 13.775, 'epoch': 0.44}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5436838865280151, 'eval_roc_auc': 0.4902279616064663, 'eval_runtime': 2.0304, 'eval_samples_per_second': 429.472, 'eval_steps_per_second': 13.79, 'epoch': 0.44}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
  9%|▉         | 413/4655 [15:01<2:35:25,  2.20s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
  9%|▉         | 413/4655 [15:01<2:35:25,  2.20s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5430792570114136, 'eval_roc_auc': 0.4902279616064663, 'eval_runtime': 2.0326, 'eval_samples_per_second': 428.999, 'eval_steps_per_second': 13.775, 'epoch': 0.44}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5427747964859009, 'eval_roc_auc': 0.49024374842131857, 'eval_runtime': 2.0358, 'eval_samples_per_second': 428.343, 'eval_steps_per_second': 13.754, 'epoch': 0.45}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.542466938495636, 'eval_roc_auc': 0.4902700597794055, 'eval_runtime': 2.0288, 'eval_samples_per_second': 429.814, 'eval_steps_per_second': 13.801, 'epoch': 0.45}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
{'eval_loss': -0.5416972041130066, 'eval_roc_auc': 0.4902226993348489, 'eval_runtime': 2.0318, 'eval_samples_per_second': 429.178, 'eval_steps_per_second': 13.781, 'epoch': 0.45}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
  9%|▉         | 424/4655 [15:27<2:34:42,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
  9%|▉         | 424/4655 [15:27<2:34:42,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5413857698440552, 'eval_roc_auc': 0.49023322387808366, 'eval_runtime': 2.0302, 'eval_samples_per_second': 429.519, 'eval_steps_per_second': 13.792, 'epoch': 0.46}
  9%|▉         | 424/4655 [15:27<2:34:42,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5410734415054321, 'eval_roc_auc': 0.49024374842131857, 'eval_runtime': 2.0289, 'eval_samples_per_second': 429.784, 'eval_steps_per_second': 13.8, 'epoch': 0.46}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5407593250274658, 'eval_roc_auc': 0.4902542729645533, 'eval_runtime': 2.0303, 'eval_samples_per_second': 429.497, 'eval_steps_per_second': 13.791, 'epoch': 0.46}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5406017899513245, 'eval_roc_auc': 0.4902647975077882, 'eval_runtime': 2.0336, 'eval_samples_per_second': 428.804, 'eval_steps_per_second': 13.769, 'epoch': 0.46}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5404449701309204, 'eval_roc_auc': 0.4902700597794057, 'eval_runtime': 2.0608, 'eval_samples_per_second': 423.133, 'eval_steps_per_second': 13.587, 'epoch': 0.46}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5401323437690735, 'eval_roc_auc': 0.49027005977940563, 'eval_runtime': 2.033, 'eval_samples_per_second': 428.922, 'eval_steps_per_second': 13.773, 'epoch': 0.47}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5398179292678833, 'eval_roc_auc': 0.49027532205102303, 'eval_runtime': 2.0316, 'eval_samples_per_second': 429.22, 'eval_steps_per_second': 13.782, 'epoch': 0.47}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5395053029060364, 'eval_roc_auc': 0.4903016334091101, 'eval_runtime': 2.0329, 'eval_samples_per_second': 428.953, 'eval_steps_per_second': 13.774, 'epoch': 0.47}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5391920804977417, 'eval_roc_auc': 0.4903068956807275, 'eval_runtime': 2.0501, 'eval_samples_per_second': 425.346, 'eval_steps_per_second': 13.658, 'epoch': 0.47}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5388805866241455, 'eval_roc_auc': 0.49028584659425783, 'eval_runtime': 2.03, 'eval_samples_per_second': 429.556, 'eval_steps_per_second': 13.793, 'epoch': 0.47}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5387244820594788, 'eval_roc_auc': 0.4902911088658752, 'eval_runtime': 2.0326, 'eval_samples_per_second': 429.003, 'eval_steps_per_second': 13.775, 'epoch': 0.47}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5385674834251404, 'eval_roc_auc': 0.4902858465942578, 'eval_runtime': 2.0302, 'eval_samples_per_second': 429.52, 'eval_steps_per_second': 13.792, 'epoch': 0.48}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
 10%|▉         | 445/4655 [16:11<2:33:56,  2.19s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 10%|▉         | 445/4655 [16:11<2:33:56,  2.19s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 10%|▉         | 445/4655 [16:11<2:33:56,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
 10%|▉         | 445/4655 [16:11<2:33:56,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5380899310112, 'eval_roc_auc': 0.4902595352361708, 'eval_runtime': 2.0336, 'eval_samples_per_second': 428.799, 'eval_steps_per_second': 13.769, 'epoch': 0.48}
 10%|▉         | 445/4655 [16:11<2:33:56,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5377718806266785, 'eval_roc_auc': 0.4902279616064663, 'eval_runtime': 2.0324, 'eval_samples_per_second': 429.057, 'eval_steps_per_second': 13.777, 'epoch': 0.48}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5374557971954346, 'eval_roc_auc': 0.4902226993348489, 'eval_runtime': 2.0296, 'eval_samples_per_second': 429.646, 'eval_steps_per_second': 13.796, 'epoch': 0.48}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
{'eval_loss': -0.5369771122932434, 'eval_roc_auc': 0.49028058432264043, 'eval_runtime': 2.0315, 'eval_samples_per_second': 429.233, 'eval_steps_per_second': 13.783, 'epoch': 0.49}
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
{'eval_loss': -0.536816418170929, 'eval_roc_auc': 0.49028058432264043, 'eval_runtime': 2.0288, 'eval_samples_per_second': 429.819, 'eval_steps_per_second': 13.802, 'epoch': 0.49}
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`embeds.``eds.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`embeds.``eds.`
{'eval_loss': -0.5363296270370483, 'eval_roc_auc': 0.4902963711374927, 'eval_runtime': 2.0363, 'eval_samples_per_second': 428.232, 'eval_steps_per_second': 13.751, 'epoch': 0.49}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`embeds.``eds.`
{'eval_loss': -0.5361678004264832, 'eval_roc_auc': 0.4903068956807275, 'eval_runtime': 2.0622, 'eval_samples_per_second': 422.855, 'eval_steps_per_second': 13.578, 'epoch': 0.49}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5360060334205627, 'eval_roc_auc': 0.4903174202239623, 'eval_runtime': 2.0299, 'eval_samples_per_second': 429.573, 'eval_steps_per_second': 13.794, 'epoch': 0.49}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5356826782226562, 'eval_roc_auc': 0.49033320703881456, 'eval_runtime': 2.0546, 'eval_samples_per_second': 424.407, 'eval_steps_per_second': 13.628, 'epoch': 0.5}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5355199575424194, 'eval_roc_auc': 0.4903489938536668, 'eval_runtime': 2.0299, 'eval_samples_per_second': 429.572, 'eval_steps_per_second': 13.794, 'epoch': 0.5}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5353569388389587, 'eval_roc_auc': 0.49033846931043196, 'eval_runtime': 2.0346, 'eval_samples_per_second': 428.576, 'eval_steps_per_second': 13.762, 'epoch': 0.5}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
 10%|▉         | 465/4655 [16:55<2:33:27,  2.20s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 10%|▉         | 465/4655 [16:55<2:33:27,  2.20s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 10%|▉         | 465/4655 [16:55<2:33:27,  2.20GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
 10%|▉         | 465/4655 [16:55<2:33:27,  2.20GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5348686575889587, 'eval_roc_auc': 0.4903542561252842, 'eval_runtime': 2.0322, 'eval_samples_per_second': 429.083, 'eval_steps_per_second': 13.778, 'epoch': 0.5}
 10%|▉         | 465/4655 [16:55<2:33:27,  2.20GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5345412492752075, 'eval_roc_auc': 0.4903700429401364, 'eval_runtime': 2.0328, 'eval_samples_per_second': 428.971, 'eval_steps_per_second': 13.774, 'epoch': 0.5}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5343769788742065, 'eval_roc_auc': 0.4903700429401364, 'eval_runtime': 2.032, 'eval_samples_per_second': 429.131, 'eval_steps_per_second': 13.779, 'epoch': 0.5}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.534214198589325, 'eval_roc_auc': 0.4903858297549887, 'eval_runtime': 2.0282, 'eval_samples_per_second': 429.928, 'eval_steps_per_second': 13.805, 'epoch': 0.5}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`embeds.``eds.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`embeds.``eds.`
{'eval_loss': -0.5330622792243958, 'eval_roc_auc': 0.49041214111307574, 'eval_runtime': 2.034, 'eval_samples_per_second': 428.706, 'eval_steps_per_second': 13.766, 'epoch': 0.51}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`embeds.``eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5327349901199341, 'eval_roc_auc': 0.49043319019954534, 'eval_runtime': 2.0328, 'eval_samples_per_second': 428.975, 'eval_steps_per_second': 13.774, 'epoch': 0.51}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.532243013381958, 'eval_roc_auc': 0.49041214111307574, 'eval_runtime': 2.0473, 'eval_samples_per_second': 425.922, 'eval_steps_per_second': 13.676, 'epoch': 0.52}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5319156050682068, 'eval_roc_auc': 0.4903726740759451, 'eval_runtime': 2.0322, 'eval_samples_per_second': 429.101, 'eval_steps_per_second': 13.778, 'epoch': 0.52}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5317521691322327, 'eval_roc_auc': 0.4903700429401364, 'eval_runtime': 2.031, 'eval_samples_per_second': 429.341, 'eval_steps_per_second': 13.786, 'epoch': 0.52}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5314247608184814, 'eval_roc_auc': 0.4903858297549886, 'eval_runtime': 2.0351, 'eval_samples_per_second': 428.479, 'eval_steps_per_second': 13.758, 'epoch': 0.52}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5310960412025452, 'eval_roc_auc': 0.4904489770143976, 'eval_runtime': 2.0325, 'eval_samples_per_second': 429.018, 'eval_steps_per_second': 13.776, 'epoch': 0.53}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
{'eval_loss': -0.5304340124130249, 'eval_roc_auc': 0.4904068788414583, 'eval_runtime': 2.0306, 'eval_samples_per_second': 429.437, 'eval_steps_per_second': 13.789, 'epoch': 0.53}
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`embeds.``eds.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`embeds.``eds.`
 11%|█         | 496/4655 [18:05<2:32:05,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
 11%|█         | 496/4655 [18:05<2:32:05,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5297672748565674, 'eval_roc_auc': 0.49043319019954534, 'eval_runtime': 2.0335, 'eval_samples_per_second': 428.822, 'eval_steps_per_second': 13.77, 'epoch': 0.53}
 11%|█         | 496/4655 [18:05<2:32:05,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5294339656829834, 'eval_roc_auc': 0.4904121411130757, 'eval_runtime': 2.0329, 'eval_samples_per_second': 428.946, 'eval_steps_per_second': 13.773, 'epoch': 0.54}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5287619233131409, 'eval_roc_auc': 0.4904384524711628, 'eval_runtime': 2.0566, 'eval_samples_per_second': 424.007, 'eval_steps_per_second': 13.615, 'epoch': 0.54}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5285950899124146, 'eval_roc_auc': 0.4904331901995454, 'eval_runtime': 2.0301, 'eval_samples_per_second': 429.535, 'eval_steps_per_second': 13.792, 'epoch': 0.54}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5284274220466614, 'eval_roc_auc': 0.49045423928601495, 'eval_runtime': 2.0315, 'eval_samples_per_second': 429.249, 'eval_steps_per_second': 13.783, 'epoch': 0.54}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
 11%|█         | 507/4655 [18:28<2:32:16,  2.20s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 11%|█         | 507/4655 [18:28<2:32:16,  2.20s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5277498364448547, 'eval_roc_auc': 0.4904910751873369, 'eval_runtime': 2.0307, 'eval_samples_per_second': 429.413, 'eval_steps_per_second': 13.788, 'epoch': 0.55}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5274115800857544, 'eval_roc_auc': 0.490517386545424, 'eval_runtime': 2.0357, 'eval_samples_per_second': 428.36, 'eval_steps_per_second': 13.755, 'epoch': 0.55}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5272422432899475, 'eval_roc_auc': 0.490517386545424, 'eval_runtime': 2.0342, 'eval_samples_per_second': 428.677, 'eval_steps_per_second': 13.765, 'epoch': 0.55}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5270717740058899, 'eval_roc_auc': 0.4905226488170414, 'eval_runtime': 2.0544, 'eval_samples_per_second': 424.451, 'eval_steps_per_second': 13.629, 'epoch': 0.55}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5269007682800293, 'eval_roc_auc': 0.4905279110886588, 'eval_runtime': 2.0327, 'eval_samples_per_second': 428.978, 'eval_steps_per_second': 13.775, 'epoch': 0.55}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
 11%|█         | 515/4655 [18:47<2:31:44,  2.20GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
 11%|█         | 515/4655 [18:47<2:31:44,  2.20GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5265612006187439, 'eval_roc_auc': 0.49053317336027613, 'eval_runtime': 2.0296, 'eval_samples_per_second': 429.636, 'eval_steps_per_second': 13.796, 'epoch': 0.55}
 11%|█         | 515/4655 [18:47<2:31:44,  2.20GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5263914465904236, 'eval_roc_auc': 0.4905121242738065, 'eval_runtime': 2.0313, 'eval_samples_per_second': 429.273, 'eval_steps_per_second': 13.784, 'epoch': 0.56}
 11%|█         | 515/4655 [18:47<2:31:44,  2.20GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5260517001152039, 'eval_roc_auc': 0.4905173865454239, 'eval_runtime': 2.0342, 'eval_samples_per_second': 428.66, 'eval_steps_per_second': 13.764, 'epoch': 0.56}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5258828997612, 'eval_roc_auc': 0.4905252799528501, 'eval_runtime': 2.0319, 'eval_samples_per_second': 429.159, 'eval_steps_per_second': 13.78, 'epoch': 0.56}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
{'eval_loss': -0.5252111554145813, 'eval_roc_auc': 0.49058579607645025, 'eval_runtime': 2.0495, 'eval_samples_per_second': 425.478, 'eval_steps_per_second': 13.662, 'epoch': 0.56}
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`embeds.``eds.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`embeds.``eds.`
 11%|█▏        | 527/4655 [19:14<2:31:09,  2.20GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
 11%|█▏        | 527/4655 [19:14<2:31:09,  2.20GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5241886377334595, 'eval_roc_auc': 0.4906489433358592, 'eval_runtime': 2.0336, 'eval_samples_per_second': 428.8, 'eval_steps_per_second': 13.769, 'epoch': 0.57}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5240164399147034, 'eval_roc_auc': 0.49064368106424183, 'eval_runtime': 2.035, 'eval_samples_per_second': 428.491, 'eval_steps_per_second': 13.759, 'epoch': 0.57}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5233281254768372, 'eval_roc_auc': 0.4906752546939463, 'eval_runtime': 2.0317, 'eval_samples_per_second': 429.202, 'eval_steps_per_second': 13.782, 'epoch': 0.57}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5231531262397766, 'eval_roc_auc': 0.4906699924223289, 'eval_runtime': 2.034, 'eval_samples_per_second': 428.704, 'eval_steps_per_second': 13.766, 'epoch': 0.58}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5229772925376892, 'eval_roc_auc': 0.4906594678790941, 'eval_runtime': 2.0354, 'eval_samples_per_second': 428.41, 'eval_steps_per_second': 13.756, 'epoch': 0.58}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.52262943983078, 'eval_roc_auc': 0.49065946787909404, 'eval_runtime': 2.0337, 'eval_samples_per_second': 428.774, 'eval_steps_per_second': 13.768, 'epoch': 0.58}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5222834944725037, 'eval_roc_auc': 0.49066473015071144, 'eval_runtime': 2.0574, 'eval_samples_per_second': 423.845, 'eval_steps_per_second': 13.61, 'epoch': 0.58}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5217653512954712, 'eval_roc_auc': 0.4906594678790941, 'eval_runtime': 2.0521, 'eval_samples_per_second': 424.923, 'eval_steps_per_second': 13.644, 'epoch': 0.58}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5215915441513062, 'eval_roc_auc': 0.4906594678790941, 'eval_runtime': 2.0282, 'eval_samples_per_second': 429.928, 'eval_steps_per_second': 13.805, 'epoch': 0.59}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5214166641235352, 'eval_roc_auc': 0.49065420560747663, 'eval_runtime': 2.0335, 'eval_samples_per_second': 428.819, 'eval_steps_per_second': 13.769, 'epoch': 0.59}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
 12%|█▏        | 547/4655 [19:58<2:30:30,  2.20GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
 12%|█▏        | 547/4655 [19:58<2:30:30,  2.20GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5207107067108154, 'eval_roc_auc': 0.49069630378041584, 'eval_runtime': 2.0272, 'eval_samples_per_second': 430.144, 'eval_steps_per_second': 13.812, 'epoch': 0.59}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5205342173576355, 'eval_roc_auc': 0.4906805169655637, 'eval_runtime': 2.0269, 'eval_samples_per_second': 430.208, 'eval_steps_per_second': 13.814, 'epoch': 0.59}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5201813578605652, 'eval_roc_auc': 0.49064368106424183, 'eval_runtime': 2.0271, 'eval_samples_per_second': 430.172, 'eval_steps_per_second': 13.813, 'epoch': 0.59}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5200046896934509, 'eval_roc_auc': 0.4906594678790941, 'eval_runtime': 2.0516, 'eval_samples_per_second': 425.037, 'eval_steps_per_second': 13.648, 'epoch': 0.6}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5198280811309814, 'eval_roc_auc': 0.49067525469394624, 'eval_runtime': 2.026, 'eval_samples_per_second': 430.397, 'eval_steps_per_second': 13.82, 'epoch': 0.6}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
{'eval_loss': -0.5192998051643372, 'eval_roc_auc': 0.49069630378041595, 'eval_runtime': 2.0253, 'eval_samples_per_second': 430.556, 'eval_steps_per_second': 13.825, 'epoch': 0.6}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
 12%|█▏        | 559/4655 [20:24<2:29:24,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
 12%|█▏        | 559/4655 [20:24<2:29:24,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5189477205276489, 'eval_roc_auc': 0.4906857792371811, 'eval_runtime': 2.0253, 'eval_samples_per_second': 430.548, 'eval_steps_per_second': 13.825, 'epoch': 0.6}
 12%|█▏        | 559/4655 [20:24<2:29:24,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5187714099884033, 'eval_roc_auc': 0.49070156605203336, 'eval_runtime': 2.0286, 'eval_samples_per_second': 429.859, 'eval_steps_per_second': 13.803, 'epoch': 0.6}
 12%|█▏        | 559/4655 [20:24<2:29:24,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5184175372123718, 'eval_roc_auc': 0.49069630378041595, 'eval_runtime': 2.0289, 'eval_samples_per_second': 429.799, 'eval_steps_per_second': 13.801, 'epoch': 0.6}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5182397961616516, 'eval_roc_auc': 0.49070682832365076, 'eval_runtime': 2.0504, 'eval_samples_per_second': 425.274, 'eval_steps_per_second': 13.656, 'epoch': 0.61}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
{'eval_loss': -0.5177044868469238, 'eval_roc_auc': 0.4907541887682074, 'eval_runtime': 2.0275, 'eval_samples_per_second': 430.089, 'eval_steps_per_second': 13.81, 'epoch': 0.61}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
 12%|█▏        | 568/4655 [20:44<2:29:20,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
 12%|█▏        | 568/4655 [20:44<2:29:20,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5173481702804565, 'eval_roc_auc': 0.4907489264965901, 'eval_runtime': 2.0323, 'eval_samples_per_second': 429.073, 'eval_steps_per_second': 13.778, 'epoch': 0.61}
 12%|█▏        | 568/4655 [20:44<2:29:20,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5169943571090698, 'eval_roc_auc': 0.49075418876820753, 'eval_runtime': 2.0263, 'eval_samples_per_second': 430.338, 'eval_steps_per_second': 13.818, 'epoch': 0.61}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5166377425193787, 'eval_roc_auc': 0.4907857623979119, 'eval_runtime': 2.026, 'eval_samples_per_second': 430.415, 'eval_steps_per_second': 13.821, 'epoch': 0.62}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5164599418640137, 'eval_roc_auc': 0.4908068114843816, 'eval_runtime': 2.0297, 'eval_samples_per_second': 429.626, 'eval_steps_per_second': 13.795, 'epoch': 0.62}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
{'eval_loss': -0.5159252882003784, 'eval_roc_auc': 0.4908331228424686, 'eval_runtime': 2.0274, 'eval_samples_per_second': 430.101, 'eval_steps_per_second': 13.811, 'epoch': 0.62}
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
{'eval_loss': -0.5157449841499329, 'eval_roc_auc': 0.4908331228424686, 'eval_runtime': 2.0261, 'eval_samples_per_second': 430.373, 'eval_steps_per_second': 13.819, 'epoch': 0.62}
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`embeds.``eds.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`embeds.``eds.`
 12%|█▏        | 580/4655 [21:10<2:28:38,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
 12%|█▏        | 580/4655 [21:10<2:28:38,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5148482322692871, 'eval_roc_auc': 0.49083838511408595, 'eval_runtime': 2.0287, 'eval_samples_per_second': 429.839, 'eval_steps_per_second': 13.802, 'epoch': 0.63}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.51466965675354, 'eval_roc_auc': 0.4908541719289382, 'eval_runtime': 2.0314, 'eval_samples_per_second': 429.27, 'eval_steps_per_second': 13.784, 'epoch': 0.63}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5144909620285034, 'eval_roc_auc': 0.49085943420055567, 'eval_runtime': 2.0545, 'eval_samples_per_second': 424.431, 'eval_steps_per_second': 13.629, 'epoch': 0.63}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5143126249313354, 'eval_roc_auc': 0.49088048328702527, 'eval_runtime': 2.0266, 'eval_samples_per_second': 430.279, 'eval_steps_per_second': 13.816, 'epoch': 0.63}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5141352415084839, 'eval_roc_auc': 0.490864696472173, 'eval_runtime': 2.0309, 'eval_samples_per_second': 429.377, 'eval_steps_per_second': 13.787, 'epoch': 0.63}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5137789845466614, 'eval_roc_auc': 0.4908699587437905, 'eval_runtime': 2.0261, 'eval_samples_per_second': 430.393, 'eval_steps_per_second': 13.82, 'epoch': 0.63}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
 13%|█▎        | 592/4655 [21:34<2:28:18,  2.19s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 13%|█▎        | 592/4655 [21:34<2:28:18,  2.19s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5123342275619507, 'eval_roc_auc': 0.4908436473857035, 'eval_runtime': 2.0305, 'eval_samples_per_second': 429.444, 'eval_steps_per_second': 13.789, 'epoch': 0.64}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5121536254882812, 'eval_roc_auc': 0.4908225982992338, 'eval_runtime': 2.0278, 'eval_samples_per_second': 430.03, 'eval_steps_per_second': 13.808, 'epoch': 0.64}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5119723677635193, 'eval_roc_auc': 0.4908225982992338, 'eval_runtime': 2.0283, 'eval_samples_per_second': 429.915, 'eval_steps_per_second': 13.805, 'epoch': 0.64}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
 13%|█▎        | 601/4655 [21:54<2:28:00,  2.19s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 13%|█▎        | 601/4655 [21:54<2:28:00,  2.19s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5112442374229431, 'eval_roc_auc': 0.490838385114086, 'eval_runtime': 2.0253, 'eval_samples_per_second': 430.547, 'eval_steps_per_second': 13.825, 'epoch': 0.65}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5110610127449036, 'eval_roc_auc': 0.4908541719289383, 'eval_runtime': 2.0218, 'eval_samples_per_second': 431.298, 'eval_steps_per_second': 13.849, 'epoch': 0.65}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5108776092529297, 'eval_roc_auc': 0.49084364738570346, 'eval_runtime': 2.0287, 'eval_samples_per_second': 429.829, 'eval_steps_per_second': 13.802, 'epoch': 0.65}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5101426839828491, 'eval_roc_auc': 0.4908436473857034, 'eval_runtime': 2.0516, 'eval_samples_per_second': 425.026, 'eval_steps_per_second': 13.648, 'epoch': 0.65}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5099600553512573, 'eval_roc_auc': 0.4908278605708512, 'eval_runtime': 2.0226, 'eval_samples_per_second': 431.126, 'eval_steps_per_second': 13.844, 'epoch': 0.66}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
 13%|█▎        | 613/4655 [22:20<2:27:27,  2.19s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 13%|█▎        | 613/4655 [22:20<2:27:27,  2.19s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5092289447784424, 'eval_roc_auc': 0.4908910078302602, 'eval_runtime': 2.0252, 'eval_samples_per_second': 430.573, 'eval_steps_per_second': 13.826, 'epoch': 0.66}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5088644027709961, 'eval_roc_auc': 0.4908752210154079, 'eval_runtime': 2.0398, 'eval_samples_per_second': 427.501, 'eval_steps_per_second': 13.727, 'epoch': 0.66}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5086808800697327, 'eval_roc_auc': 0.49089627010187753, 'eval_runtime': 2.0283, 'eval_samples_per_second': 429.919, 'eval_steps_per_second': 13.805, 'epoch': 0.66}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5084960460662842, 'eval_roc_auc': 0.49090679464511244, 'eval_runtime': 2.0255, 'eval_samples_per_second': 430.515, 'eval_steps_per_second': 13.824, 'epoch': 0.66}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`embeds.``eds.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`embeds.``eds.`
{'eval_loss': -0.5075739026069641, 'eval_roc_auc': 0.49091731918834725, 'eval_runtime': 2.0513, 'eval_samples_per_second': 425.086, 'eval_steps_per_second': 13.65, 'epoch': 0.67}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`embeds.``eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5072032809257507, 'eval_roc_auc': 0.490901532373495, 'eval_runtime': 2.0286, 'eval_samples_per_second': 429.856, 'eval_steps_per_second': 13.803, 'epoch': 0.67}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5070181488990784, 'eval_roc_auc': 0.4908962701018776, 'eval_runtime': 2.0282, 'eval_samples_per_second': 429.928, 'eval_steps_per_second': 13.805, 'epoch': 0.67}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5064607858657837, 'eval_roc_auc': 0.49091205691672984, 'eval_runtime': 2.0263, 'eval_samples_per_second': 430.333, 'eval_steps_per_second': 13.818, 'epoch': 0.68}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5060903429985046, 'eval_roc_auc': 0.4908910078302602, 'eval_runtime': 2.0258, 'eval_samples_per_second': 430.438, 'eval_steps_per_second': 13.821, 'epoch': 0.68}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
 14%|█▎        | 634/4655 [23:06<2:26:31,  2.19s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 14%|█▎        | 634/4655 [23:06<2:26:31,  2.19s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5053495168685913, 'eval_roc_auc': 0.4908804832870254, 'eval_runtime': 2.0314, 'eval_samples_per_second': 429.268, 'eval_steps_per_second': 13.784, 'epoch': 0.68}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5051634311676025, 'eval_roc_auc': 0.4908699587437906, 'eval_runtime': 2.0456, 'eval_samples_per_second': 426.28, 'eval_steps_per_second': 13.688, 'epoch': 0.68}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.5049771666526794, 'eval_roc_auc': 0.4908646964721732, 'eval_runtime': 2.0487, 'eval_samples_per_second': 425.636, 'eval_steps_per_second': 13.667, 'epoch': 0.68}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5045999884605408, 'eval_roc_auc': 0.49084890965732086, 'eval_runtime': 2.0264, 'eval_samples_per_second': 430.312, 'eval_steps_per_second': 13.817, 'epoch': 0.69}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.504411518573761, 'eval_roc_auc': 0.490812073755999, 'eval_runtime': 2.026, 'eval_samples_per_second': 430.414, 'eval_steps_per_second': 13.821, 'epoch': 0.69}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
{'eval_loss': -0.5038445591926575, 'eval_roc_auc': 0.490812073755999, 'eval_runtime': 2.0245, 'eval_samples_per_second': 430.714, 'eval_steps_per_second': 13.83, 'epoch': 0.69}
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect GGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5032748579978943, 'eval_roc_auc': 0.4908068114843816, 'eval_runtime': 2.0295, 'eval_samples_per_second': 429.654, 'eval_steps_per_second': 13.796, 'epoch': 0.69}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5030831694602966, 'eval_roc_auc': 0.49080681148438154, 'eval_runtime': 2.024, 'eval_samples_per_second': 430.826, 'eval_steps_per_second': 13.834, 'epoch': 0.69}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5026976466178894, 'eval_roc_auc': 0.4907989180769554, 'eval_runtime': 2.023, 'eval_samples_per_second': 431.041, 'eval_steps_per_second': 13.841, 'epoch': 0.7}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
{'eval_loss': -0.50211501121521, 'eval_roc_auc': 0.49080154921276414, 'eval_runtime': 2.0273, 'eval_samples_per_second': 430.136, 'eval_steps_per_second': 13.812, 'epoch': 0.7}
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`embeds.``eds.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`embeds.``eds.`
 14%|█▍        | 655/4655 [23:54<2:25:56,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
 14%|█▍        | 655/4655 [23:54<2:25:56,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
 14%|█▍        | 655/4655 [23:54<2:25:56,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5013386011123657, 'eval_roc_auc': 0.490812073755999, 'eval_runtime': 2.0243, 'eval_samples_per_second': 430.767, 'eval_steps_per_second': 13.832, 'epoch': 0.7}
 14%|█▍        | 655/4655 [23:54<2:25:56,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5011456608772278, 'eval_roc_auc': 0.4908068114843816, 'eval_runtime': 2.0468, 'eval_samples_per_second': 426.036, 'eval_steps_per_second': 13.68, 'epoch': 0.71}
 14%|█▍        | 655/4655 [23:54<2:25:56,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5007585883140564, 'eval_roc_auc': 0.49080681148438154, 'eval_runtime': 2.0282, 'eval_samples_per_second': 429.942, 'eval_steps_per_second': 13.805, 'epoch': 0.71}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5005648732185364, 'eval_roc_auc': 0.49082786057085126, 'eval_runtime': 2.0272, 'eval_samples_per_second': 430.144, 'eval_steps_per_second': 13.812, 'epoch': 0.71}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5003712773323059, 'eval_roc_auc': 0.490812073755999, 'eval_runtime': 2.0257, 'eval_samples_per_second': 430.464, 'eval_steps_per_second': 13.822, 'epoch': 0.71}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.5001779198646545, 'eval_roc_auc': 0.490812073755999, 'eval_runtime': 2.0264, 'eval_samples_per_second': 430.318, 'eval_steps_per_second': 13.818, 'epoch': 0.71}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
{'eval_loss': -0.499790221452713, 'eval_roc_auc': 0.49079365580533807, 'eval_runtime': 2.0484, 'eval_samples_per_second': 425.697, 'eval_steps_per_second': 13.669, 'epoch': 0.71}
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
{'eval_loss': -0.49940553307533264, 'eval_roc_auc': 0.490759451039825, 'eval_runtime': 2.0266, 'eval_samples_per_second': 430.287, 'eval_steps_per_second': 13.817, 'epoch': 0.72}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
 14%|█▍        | 667/4655 [24:21<2:25:35,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
 14%|█▍        | 667/4655 [24:21<2:25:35,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
 14%|█▍        | 667/4655 [24:21<2:25:35,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.4986385107040405, 'eval_roc_auc': 0.4907910246695293, 'eval_runtime': 2.0236, 'eval_samples_per_second': 430.911, 'eval_steps_per_second': 13.837, 'epoch': 0.72}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
{'eval_loss': -0.498055636882782, 'eval_roc_auc': 0.49084890965732086, 'eval_runtime': 2.0222, 'eval_samples_per_second': 431.209, 'eval_steps_per_second': 13.846, 'epoch': 0.72}
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`embeds.``eds.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`embeds.``eds.`
 15%|█▍        | 676/4655 [24:40<2:25:01,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
 15%|█▍        | 676/4655 [24:40<2:25:01,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.4972645938396454, 'eval_roc_auc': 0.49084364738570346, 'eval_runtime': 2.0466, 'eval_samples_per_second': 426.068, 'eval_steps_per_second': 13.681, 'epoch': 0.73}
 15%|█▍        | 676/4655 [24:40<2:25:01,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.49706533551216125, 'eval_roc_auc': 0.490838385114086, 'eval_runtime': 2.0491, 'eval_samples_per_second': 425.546, 'eval_steps_per_second': 13.664, 'epoch': 0.73}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.49686628580093384, 'eval_roc_auc': 0.49085943420055567, 'eval_runtime': 2.0255, 'eval_samples_per_second': 430.517, 'eval_steps_per_second': 13.824, 'epoch': 0.73}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.4966663718223572, 'eval_roc_auc': 0.49083838511408606, 'eval_runtime': 2.0302, 'eval_samples_per_second': 429.523, 'eval_steps_per_second': 13.792, 'epoch': 0.73}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.49626874923706055, 'eval_roc_auc': 0.49084890965732086, 'eval_runtime': 2.0259, 'eval_samples_per_second': 430.426, 'eval_steps_per_second': 13.821, 'epoch': 0.73}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
{'eval_loss': -0.4956730902194977, 'eval_roc_auc': 0.4908646964721731, 'eval_runtime': 2.0269, 'eval_samples_per_second': 430.215, 'eval_steps_per_second': 13.814, 'epoch': 0.74}
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`embeds.``eds.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`embeds.``eds.`
 15%|█▍        | 688/4655 [25:07<2:24:47,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
 15%|█▍        | 688/4655 [25:07<2:24:47,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.4948727786540985, 'eval_roc_auc': 0.4908804832870254, 'eval_runtime': 2.0269, 'eval_samples_per_second': 430.216, 'eval_steps_per_second': 13.814, 'epoch': 0.74}
 15%|█▍        | 688/4655 [25:07<2:24:47,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.49467265605926514, 'eval_roc_auc': 0.4908962701018776, 'eval_runtime': 2.0236, 'eval_samples_per_second': 430.919, 'eval_steps_per_second': 13.837, 'epoch': 0.74}
 15%|█▍        | 688/4655 [25:07<2:24:47,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
 15%|█▍        | 688/4655 [25:07<2:24:47,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.49427494406700134, 'eval_roc_auc': 0.49086995874379047, 'eval_runtime': 2.0537, 'eval_samples_per_second': 424.593, 'eval_steps_per_second': 13.634, 'epoch': 0.74}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.49407511949539185, 'eval_roc_auc': 0.4908752210154079, 'eval_runtime': 2.0253, 'eval_samples_per_second': 430.554, 'eval_steps_per_second': 13.825, 'epoch': 0.74}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
{'eval_loss': -0.49347931146621704, 'eval_roc_auc': 0.49090679464511233, 'eval_runtime': 2.0262, 'eval_samples_per_second': 430.358, 'eval_steps_per_second': 13.819, 'epoch': 0.75}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
 15%|█▍        | 698/4655 [25:27<2:24:19,  2.19s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 15%|█▍        | 698/4655 [25:27<2:24:19,  2.19s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 15%|█▍        | 698/4655 [25:27<2:24:19,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.4926820695400238, 'eval_roc_auc': 0.49089627010187753, 'eval_runtime': 2.027, 'eval_samples_per_second': 430.193, 'eval_steps_per_second': 13.814, 'epoch': 0.75}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.4924831688404083, 'eval_roc_auc': 0.4908962701018776, 'eval_runtime': 2.031, 'eval_samples_per_second': 429.347, 'eval_steps_per_second': 13.786, 'epoch': 0.75}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.4920843243598938, 'eval_roc_auc': 0.4908910078302602, 'eval_runtime': 2.028, 'eval_samples_per_second': 429.97, 'eval_steps_per_second': 13.806, 'epoch': 0.76}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.4914841949939728, 'eval_roc_auc': 0.4908278605708512, 'eval_runtime': 2.0304, 'eval_samples_per_second': 429.465, 'eval_steps_per_second': 13.79, 'epoch': 0.76}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.49128463864326477, 'eval_roc_auc': 0.490812073755999, 'eval_runtime': 2.031, 'eval_samples_per_second': 429.352, 'eval_steps_per_second': 13.787, 'epoch': 0.76}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.49108436703681946, 'eval_roc_auc': 0.490812073755999, 'eval_runtime': 2.0314, 'eval_samples_per_second': 429.268, 'eval_steps_per_second': 13.784, 'epoch': 0.76}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
 15%|█▌        | 710/4655 [25:53<2:23:59,  2.19s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 15%|█▌        | 710/4655 [25:53<2:23:59,  2.19s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 15%|█▌        | 710/4655 [25:53<2:23:59,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
 15%|█▌        | 710/4655 [25:53<2:23:59,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
 15%|█▌        | 710/4655 [25:53<2:23:59,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.4904904365539551, 'eval_roc_auc': 0.49083838511408606, 'eval_runtime': 2.0274, 'eval_samples_per_second': 430.107, 'eval_steps_per_second': 13.811, 'epoch': 0.76}
 15%|█▌        | 710/4655 [25:53<2:23:59,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.4902935326099396, 'eval_roc_auc': 0.4908541719289383, 'eval_runtime': 2.0292, 'eval_samples_per_second': 429.722, 'eval_steps_per_second': 13.798, 'epoch': 0.76}
 15%|█▌        | 710/4655 [25:53<2:23:59,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.4900958240032196, 'eval_roc_auc': 0.4908489096573209, 'eval_runtime': 2.0284, 'eval_samples_per_second': 429.889, 'eval_steps_per_second': 13.804, 'epoch': 0.77}
 15%|█▌        | 710/4655 [25:53<2:23:59,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.48969966173171997, 'eval_roc_auc': 0.4908331228424686, 'eval_runtime': 2.0378, 'eval_samples_per_second': 427.916, 'eval_steps_per_second': 13.74, 'epoch': 0.77}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.48950135707855225, 'eval_roc_auc': 0.4908173360276164, 'eval_runtime': 2.0319, 'eval_samples_per_second': 429.15, 'eval_steps_per_second': 13.78, 'epoch': 0.77}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.48930397629737854, 'eval_roc_auc': 0.49081207375599895, 'eval_runtime': 2.0272, 'eval_samples_per_second': 430.144, 'eval_steps_per_second': 13.812, 'epoch': 0.77}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
 15%|█▌        | 719/4655 [26:13<2:23:46,  2.19s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 15%|█▌        | 719/4655 [26:13<2:23:46,  2.19s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.4885069727897644, 'eval_roc_auc': 0.49079102466952934, 'eval_runtime': 2.0307, 'eval_samples_per_second': 429.409, 'eval_steps_per_second': 13.788, 'epoch': 0.77}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.48810532689094543, 'eval_roc_auc': 0.4908015492127642, 'eval_runtime': 2.0326, 'eval_samples_per_second': 429.009, 'eval_steps_per_second': 13.776, 'epoch': 0.78}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.4875023663043976, 'eval_roc_auc': 0.49081733602761635, 'eval_runtime': 2.0299, 'eval_samples_per_second': 429.575, 'eval_steps_per_second': 13.794, 'epoch': 0.78}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
{'eval_loss': -0.4868948459625244, 'eval_roc_auc': 0.4908436473857035, 'eval_runtime': 2.0315, 'eval_samples_per_second': 429.249, 'eval_steps_per_second': 13.783, 'epoch': 0.78}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
 16%|█▌        | 730/4655 [26:39<2:23:16,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
 16%|█▌        | 730/4655 [26:39<2:23:16,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.48648878931999207, 'eval_roc_auc': 0.4908068114843816, 'eval_runtime': 2.0265, 'eval_samples_per_second': 430.301, 'eval_steps_per_second': 13.817, 'epoch': 0.79}
 16%|█▌        | 730/4655 [26:39<2:23:16,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.48608216643333435, 'eval_roc_auc': 0.49079628694114674, 'eval_runtime': 2.0509, 'eval_samples_per_second': 425.174, 'eval_steps_per_second': 13.652, 'epoch': 0.79}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.48567211627960205, 'eval_roc_auc': 0.49079628694114674, 'eval_runtime': 2.0298, 'eval_samples_per_second': 429.594, 'eval_steps_per_second': 13.794, 'epoch': 0.79}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.48546674847602844, 'eval_roc_auc': 0.49079102466952934, 'eval_runtime': 2.0266, 'eval_samples_per_second': 430.273, 'eval_steps_per_second': 13.816, 'epoch': 0.79}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
{'eval_loss': -0.4848470389842987, 'eval_roc_auc': 0.4907594510398249, 'eval_runtime': 2.0346, 'eval_samples_per_second': 428.595, 'eval_steps_per_second': 13.762, 'epoch': 0.79}
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.48443523049354553, 'eval_roc_auc': 0.49080154921276414, 'eval_runtime': 2.028, 'eval_samples_per_second': 429.975, 'eval_steps_per_second': 13.807, 'epoch': 0.8}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.48402631282806396, 'eval_roc_auc': 0.4907883935337206, 'eval_runtime': 2.0246, 'eval_samples_per_second': 430.703, 'eval_steps_per_second': 13.83, 'epoch': 0.8}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.4838205873966217, 'eval_roc_auc': 0.49080681148438154, 'eval_runtime': 2.0267, 'eval_samples_per_second': 430.25, 'eval_steps_per_second': 13.815, 'epoch': 0.8}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.4836154282093048, 'eval_roc_auc': 0.4908120737559989, 'eval_runtime': 2.0291, 'eval_samples_per_second': 429.756, 'eval_steps_per_second': 13.8, 'epoch': 0.8}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
{'eval_loss': -0.48299968242645264, 'eval_roc_auc': 0.4908331228424686, 'eval_runtime': 2.0257, 'eval_samples_per_second': 430.464, 'eval_steps_per_second': 13.822, 'epoch': 0.8}
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
{'eval_loss': -0.4825916886329651, 'eval_roc_auc': 0.49083312284246866, 'eval_runtime': 2.027, 'eval_samples_per_second': 430.182, 'eval_steps_per_second': 13.813, 'epoch': 0.81}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
 16%|█▌        | 751/4655 [27:25<2:22:34,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
 16%|█▌        | 751/4655 [27:25<2:22:34,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.48218396306037903, 'eval_roc_auc': 0.4908357539782774, 'eval_runtime': 2.0282, 'eval_samples_per_second': 429.936, 'eval_steps_per_second': 13.805, 'epoch': 0.81}
 16%|█▌        | 751/4655 [27:25<2:22:34,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
 16%|█▌        | 751/4655 [27:25<2:22:34,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.48198202252388, 'eval_roc_auc': 0.4908225982992338, 'eval_runtime': 2.0289, 'eval_samples_per_second': 429.794, 'eval_steps_per_second': 13.801, 'epoch': 0.81}
 16%|█▌        | 751/4655 [27:25<2:22:34,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.4815770387649536, 'eval_roc_auc': 0.4908594342005557, 'eval_runtime': 2.0259, 'eval_samples_per_second': 430.417, 'eval_steps_per_second': 13.821, 'epoch': 0.81}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.4813748300075531, 'eval_roc_auc': 0.4908910078302602, 'eval_runtime': 2.028, 'eval_samples_per_second': 429.98, 'eval_steps_per_second': 13.807, 'epoch': 0.81}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
{'eval_loss': -0.4805586338043213, 'eval_roc_auc': 0.49091205691672984, 'eval_runtime': 2.0268, 'eval_samples_per_second': 430.226, 'eval_steps_per_second': 13.815, 'epoch': 0.82}
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
{'eval_loss': -0.48014649748802185, 'eval_roc_auc': 0.4908857455586427, 'eval_runtime': 2.0259, 'eval_samples_per_second': 430.423, 'eval_steps_per_second': 13.821, 'epoch': 0.82}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
 16%|█▋        | 764/4655 [27:51<2:21:53,  2.19s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 16%|█▋        | 764/4655 [27:51<2:21:53,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
 16%|█▋        | 764/4655 [27:51<2:21:53,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.4797303378582001, 'eval_roc_auc': 0.4908910078302602, 'eval_runtime': 2.0254, 'eval_samples_per_second': 430.541, 'eval_steps_per_second': 13.825, 'epoch': 0.82}
 16%|█▋        | 764/4655 [27:51<2:21:53,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.47952067852020264, 'eval_roc_auc': 0.4909120569167298, 'eval_runtime': 2.0265, 'eval_samples_per_second': 430.291, 'eval_steps_per_second': 13.817, 'epoch': 0.82}
 16%|█▋        | 764/4655 [27:51<2:21:53,  2.19GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.47869229316711426, 'eval_roc_auc': 0.49090679464511244, 'eval_runtime': 2.025, 'eval_samples_per_second': 430.613, 'eval_steps_per_second': 13.827, 'epoch': 0.83}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.4784879684448242, 'eval_roc_auc': 0.49089627010187764, 'eval_runtime': 2.0286, 'eval_samples_per_second': 429.86, 'eval_steps_per_second': 13.803, 'epoch': 0.83}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.4782835841178894, 'eval_roc_auc': 0.49091731918834725, 'eval_runtime': 2.0292, 'eval_samples_per_second': 429.734, 'eval_steps_per_second': 13.799, 'epoch': 0.83}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
 17%|█▋        | 773/4655 [28:11<2:21:39,  2.19s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 17%|█▋        | 773/4655 [28:11<2:21:39,  2.19s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.4776693284511566, 'eval_roc_auc': 0.4908699587437905, 'eval_runtime': 2.0429, 'eval_samples_per_second': 426.842, 'eval_steps_per_second': 13.706, 'epoch': 0.83}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.4770461320877075, 'eval_roc_auc': 0.49084890965732086, 'eval_runtime': 2.0253, 'eval_samples_per_second': 430.554, 'eval_steps_per_second': 13.825, 'epoch': 0.83}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.47684043645858765, 'eval_roc_auc': 0.49085154079312954, 'eval_runtime': 2.0236, 'eval_samples_per_second': 430.907, 'eval_steps_per_second': 13.836, 'epoch': 0.84}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.4762234091758728, 'eval_roc_auc': 0.4908594342005557, 'eval_runtime': 2.027, 'eval_samples_per_second': 430.197, 'eval_steps_per_second': 13.814, 'epoch': 0.84}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.4760192036628723, 'eval_roc_auc': 0.49088311442283405, 'eval_runtime': 2.0255, 'eval_samples_per_second': 430.516, 'eval_steps_per_second': 13.824, 'epoch': 0.84}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
 17%|█▋        | 785/4655 [28:37<2:21:04,  2.19s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 17%|█▋        | 785/4655 [28:37<2:21:04,  2.19s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.4749831557273865, 'eval_roc_auc': 0.4908489096573209, 'eval_runtime': 2.0263, 'eval_samples_per_second': 430.347, 'eval_steps_per_second': 13.818, 'epoch': 0.85}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.4747742712497711, 'eval_roc_auc': 0.4908673276079818, 'eval_runtime': 2.0476, 'eval_samples_per_second': 425.858, 'eval_steps_per_second': 13.674, 'epoch': 0.85}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.4745636582374573, 'eval_roc_auc': 0.49089627010187764, 'eval_runtime': 2.0274, 'eval_samples_per_second': 430.101, 'eval_steps_per_second': 13.811, 'epoch': 0.85}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.4743539094924927, 'eval_roc_auc': 0.49088837669445146, 'eval_runtime': 2.0273, 'eval_samples_per_second': 430.134, 'eval_steps_per_second': 13.812, 'epoch': 0.85}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`embeds.``eds.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`embeds.``eds.`
{'eval_loss': -0.4733014702796936, 'eval_roc_auc': 0.4908804832870254, 'eval_runtime': 2.0268, 'eval_samples_per_second': 430.243, 'eval_steps_per_second': 13.815, 'epoch': 0.85}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`embeds.``eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.4728764295578003, 'eval_roc_auc': 0.4908910078302602, 'eval_runtime': 2.0232, 'eval_samples_per_second': 431.008, 'eval_steps_per_second': 13.84, 'epoch': 0.86}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.47266384959220886, 'eval_roc_auc': 0.4908752210154079, 'eval_runtime': 2.0268, 'eval_samples_per_second': 430.224, 'eval_steps_per_second': 13.815, 'epoch': 0.86}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.47202175855636597, 'eval_roc_auc': 0.4908094426201903, 'eval_runtime': 2.028, 'eval_samples_per_second': 429.974, 'eval_steps_per_second': 13.807, 'epoch': 0.86}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.4715935289859772, 'eval_roc_auc': 0.4908225982992338, 'eval_runtime': 2.0271, 'eval_samples_per_second': 430.171, 'eval_steps_per_second': 13.813, 'epoch': 0.86}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
 17%|█▋        | 806/4655 [29:23<2:20:30,  2.19s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 17%|█▋        | 806/4655 [29:23<2:20:30,  2.19s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.4705122113227844, 'eval_roc_auc': 0.49087522101540787, 'eval_runtime': 2.0269, 'eval_samples_per_second': 430.218, 'eval_steps_per_second': 13.814, 'epoch': 0.87}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.47029662132263184, 'eval_roc_auc': 0.49085943420055567, 'eval_runtime': 2.0493, 'eval_samples_per_second': 425.508, 'eval_steps_per_second': 13.663, 'epoch': 0.87}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.4700823426246643, 'eval_roc_auc': 0.49084890965732086, 'eval_runtime': 2.0257, 'eval_samples_per_second': 430.462, 'eval_steps_per_second': 13.822, 'epoch': 0.87}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.4698677361011505, 'eval_roc_auc': 0.49085417192893827, 'eval_runtime': 2.0281, 'eval_samples_per_second': 429.951, 'eval_steps_per_second': 13.806, 'epoch': 0.87}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.46965301036834717, 'eval_roc_auc': 0.49084890965732086, 'eval_runtime': 2.0255, 'eval_samples_per_second': 430.514, 'eval_steps_per_second': 13.824, 'epoch': 0.87}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
{'eval_loss': -0.4687899053096771, 'eval_roc_auc': 0.49084890965732086, 'eval_runtime': 2.0642, 'eval_samples_per_second': 422.447, 'eval_steps_per_second': 13.565, 'epoch': 0.88}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ng tokens in conjunction with `inputs_embeds.``eds.`
{'eval_loss': -0.46857479214668274, 'eval_roc_auc': 0.49085417192893827, 'eval_runtime': 2.0277, 'eval_samples_per_second': 430.037, 'eval_steps_per_second': 13.809, 'epoch': 0.88}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.46836042404174805, 'eval_roc_auc': 0.49084364738570346, 'eval_runtime': 2.0284, 'eval_samples_per_second': 429.885, 'eval_steps_per_second': 13.804, 'epoch': 0.88}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.4679354429244995, 'eval_roc_auc': 0.49084364738570346, 'eval_runtime': 2.026, 'eval_samples_per_second': 430.406, 'eval_steps_per_second': 13.82, 'epoch': 0.88}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.46729734539985657, 'eval_roc_auc': 0.4908752210154079, 'eval_runtime': 2.0275, 'eval_samples_per_second': 430.089, 'eval_steps_per_second': 13.81, 'epoch': 0.88}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.4670841097831726, 'eval_roc_auc': 0.4908699587437906, 'eval_runtime': 2.0261, 'eval_samples_per_second': 430.387, 'eval_steps_per_second': 13.82, 'epoch': 0.89}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
 18%|█▊        | 827/4655 [30:09<2:19:35,  2.19s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 18%|█▊        | 827/4655 [30:09<2:19:35,  2.19s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.4662272036075592, 'eval_roc_auc': 0.4908962701018776, 'eval_runtime': 2.031, 'eval_samples_per_second': 429.347, 'eval_steps_per_second': 13.786, 'epoch': 0.89}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.46601152420043945, 'eval_roc_auc': 0.4908857455586428, 'eval_runtime': 2.0642, 'eval_samples_per_second': 422.44, 'eval_steps_per_second': 13.565, 'epoch': 0.89}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.46579644083976746, 'eval_roc_auc': 0.4908752210154079, 'eval_runtime': 2.0272, 'eval_samples_per_second': 430.15, 'eval_steps_per_second': 13.812, 'epoch': 0.89}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.46558085083961487, 'eval_roc_auc': 0.4908804832870253, 'eval_runtime': 2.0327, 'eval_samples_per_second': 428.986, 'eval_steps_per_second': 13.775, 'epoch': 0.89}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.4653684198856354, 'eval_roc_auc': 0.4908804832870253, 'eval_runtime': 2.0286, 'eval_samples_per_second': 429.856, 'eval_steps_per_second': 13.803, 'epoch': 0.89}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.4651559293270111, 'eval_roc_auc': 0.49090679464511233, 'eval_runtime': 2.0323, 'eval_samples_per_second': 429.065, 'eval_steps_per_second': 13.777, 'epoch': 0.89}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.4649433493614197, 'eval_roc_auc': 0.4908910078302602, 'eval_runtime': 2.0301, 'eval_samples_per_second': 429.541, 'eval_steps_per_second': 13.793, 'epoch': 0.9}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.4645162522792816, 'eval_roc_auc': 0.4909146880525385, 'eval_runtime': 2.0276, 'eval_samples_per_second': 430.061, 'eval_steps_per_second': 13.809, 'epoch': 0.9}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.``eds.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`embeds.``eds.`
GPT2ForSequenceClassification will notGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`embeds.``eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`embeds.``eds.`
{'eval_loss': -0.46387413144111633, 'eval_roc_auc': 0.4909752041761387, 'eval_runtime': 2.0239, 'eval_samples_per_second': 430.862, 'eval_steps_per_second': 13.835, 'epoch': 0.9}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`embeds.``eds.`
{'eval_loss': -0.46365803480148315, 'eval_roc_auc': 0.49096994190452137, 'eval_runtime': 2.0245, 'eval_samples_per_second': 430.734, 'eval_steps_per_second': 13.831, 'epoch': 0.9}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`s in conjunction with `inputs_embeds.`embeds.``eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.4632222354412079, 'eval_roc_auc': 0.49099625326260843, 'eval_runtime': 2.0281, 'eval_samples_per_second': 429.969, 'eval_steps_per_second': 13.806, 'epoch': 0.9}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.4627860486507416, 'eval_roc_auc': 0.4910278268923129, 'eval_runtime': 2.0286, 'eval_samples_per_second': 429.855, 'eval_steps_per_second': 13.803, 'epoch': 0.91}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.46256721019744873, 'eval_roc_auc': 0.4910278268923129, 'eval_runtime': 2.0288, 'eval_samples_per_second': 429.81, 'eval_steps_per_second': 13.801, 'epoch': 0.91}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.4623475968837738, 'eval_roc_auc': 0.49100677780584323, 'eval_runtime': 2.0249, 'eval_samples_per_second': 430.64, 'eval_steps_per_second': 13.828, 'epoch': 0.91}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
 18%|█▊        | 848/4655 [30:55<2:18:56,  2.19s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 18%|█▊        | 848/4655 [30:55<2:18:56,  2.19s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.4612455368041992, 'eval_roc_auc': 0.49104887597878255, 'eval_runtime': 2.0264, 'eval_samples_per_second': 430.319, 'eval_steps_per_second': 13.818, 'epoch': 0.91}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.4610244929790497, 'eval_roc_auc': 0.4910541382503999, 'eval_runtime': 2.0271, 'eval_samples_per_second': 430.163, 'eval_steps_per_second': 13.813, 'epoch': 0.92}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.46080371737480164, 'eval_roc_auc': 0.49103835143554775, 'eval_runtime': 2.0252, 'eval_samples_per_second': 430.566, 'eval_steps_per_second': 13.826, 'epoch': 0.92}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.4605819880962372, 'eval_roc_auc': 0.4910646627936347, 'eval_runtime': 2.0258, 'eval_samples_per_second': 430.455, 'eval_steps_per_second': 13.822, 'epoch': 0.92}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.460138738155365, 'eval_roc_auc': 0.4910488759787825, 'eval_runtime': 2.0255, 'eval_samples_per_second': 430.501, 'eval_steps_per_second': 13.823, 'epoch': 0.92}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.45991864800453186, 'eval_roc_auc': 0.49102782689231284, 'eval_runtime': 2.0505, 'eval_samples_per_second': 425.269, 'eval_steps_per_second': 13.655, 'epoch': 0.92}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.45969825983047485, 'eval_roc_auc': 0.49103835143554775, 'eval_runtime': 2.0258, 'eval_samples_per_second': 430.457, 'eval_steps_per_second': 13.822, 'epoch': 0.92}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
 18%|█▊        | 860/4655 [31:21<2:18:35,  2.19s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
 18%|█▊        | 860/4655 [31:21<2:18:35,  2.19s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.4590400159358978, 'eval_roc_auc': 0.49104887597878244, 'eval_runtime': 2.026, 'eval_samples_per_second': 430.404, 'eval_steps_per_second': 13.82, 'epoch': 0.92}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.45882171392440796, 'eval_roc_auc': 0.4910278268923129, 'eval_runtime': 2.0256, 'eval_samples_per_second': 430.485, 'eval_steps_per_second': 13.823, 'epoch': 0.93}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.45839062333106995, 'eval_roc_auc': 0.49106992506525216, 'eval_runtime': 2.0283, 'eval_samples_per_second': 429.923, 'eval_steps_per_second': 13.805, 'epoch': 0.93}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.4581734836101532, 'eval_roc_auc': 0.49106992506525216, 'eval_runtime': 2.0272, 'eval_samples_per_second': 430.146, 'eval_steps_per_second': 13.812, 'epoch': 0.93}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.45751819014549255, 'eval_roc_auc': 0.4911067609665741, 'eval_runtime': 2.0284, 'eval_samples_per_second': 429.892, 'eval_steps_per_second': 13.804, 'epoch': 0.93}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.45708227157592773, 'eval_roc_auc': 0.4910646627936348, 'eval_runtime': 2.0503, 'eval_samples_per_second': 425.302, 'eval_steps_per_second': 13.656, 'epoch': 0.93}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.4568652808666229, 'eval_roc_auc': 0.49106466279363475, 'eval_runtime': 2.0292, 'eval_samples_per_second': 429.728, 'eval_steps_per_second': 13.799, 'epoch': 0.94}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.45643097162246704, 'eval_roc_auc': 0.49105940052201735, 'eval_runtime': 2.0264, 'eval_samples_per_second': 430.315, 'eval_steps_per_second': 13.817, 'epoch': 0.94}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.45621171593666077, 'eval_roc_auc': 0.49104887597878255, 'eval_runtime': 2.0268, 'eval_samples_per_second': 430.228, 'eval_steps_per_second': 13.815, 'epoch': 0.94}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.45555463433265686, 'eval_roc_auc': 0.49103572029973896, 'eval_runtime': 2.0227, 'eval_samples_per_second': 431.107, 'eval_steps_per_second': 13.843, 'epoch': 0.94}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.4553370475769043, 'eval_roc_auc': 0.4910278268923129, 'eval_runtime': 2.0263, 'eval_samples_per_second': 430.338, 'eval_steps_per_second': 13.818, 'epoch': 0.94}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.4551195204257965, 'eval_roc_auc': 0.4910015155342258, 'eval_runtime': 2.0229, 'eval_samples_per_second': 431.055, 'eval_steps_per_second': 13.841, 'epoch': 0.94}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
 19%|█▉        | 881/4655 [32:07<2:17:28,  2.19s/it]GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
{'eval_loss': -0.45468419790267944, 'eval_roc_auc': 0.4909857287193736, 'eval_runtime': 2.0245, 'eval_samples_per_second': 430.734, 'eval_steps_per_second': 13.831, 'epoch': 0.95}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.` padding tokens in conjunction with `inputs_embeds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.4542507827281952, 'eval_roc_auc': 0.49100151553422583, 'eval_runtime': 2.0264, 'eval_samples_per_second': 430.313, 'eval_steps_per_second': 13.817, 'epoch': 0.95}
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.4538158178329468, 'eval_roc_auc': 0.4910330891639303, 'eval_runtime': 2.0274, 'eval_samples_per_second': 430.1, 'eval_steps_per_second': 13.811, 'epoch': 0.95}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
{'eval_loss': -0.45359620451927185, 'eval_roc_auc': 0.49100677780584323, 'eval_runtime': 2.0264, 'eval_samples_per_second': 430.322, 'eval_steps_per_second': 13.818, 'epoch': 0.95}
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect pGPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`eds.`
GPT2ForSequenceClassification will not detect padding tokens in `inputs_embeds`. Results may be unexpected if using padding tokens in conjunction with `inputs_embeds.`ing tokens in conjunction with `inputs_embeds.`eds.`
